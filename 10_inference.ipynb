{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0de904",
   "metadata": {},
   "source": [
    "Dans ce script, nous allons tester différents modèles de type convolution Nelle pour examiner leur performance. Nous allons ensuite tester s'ils sont robustes lorsqu'on applique une rotation à l'image d'entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb6e14-6ce3-481d-9afc-61b1cfee1168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T10:45:23.376798Z",
     "iopub.status.busy": "2025-04-26T10:45:23.376511Z",
     "iopub.status.idle": "2025-04-26T10:45:36.118070Z",
     "shell.execute_reply": "2025-04-26T10:45:36.117553Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import retinoto_py as fovea\n",
    "\n",
    "args = fovea.Params()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68612db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f4302",
   "metadata": {},
   "source": [
    "# testing each network on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "VAL_IMAGE_DIR = args.DATAROOT / 'Imagenet_full' / 'train'\n",
    "\n",
    "# --- 3. Load the Pre-trained ResNet Model ---\n",
    "# We'll use ResNet50, a powerful and common choice.\n",
    "# `pretrained=True` downloads the model weights trained on ImageNet.\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Move the model to the selected device (GPU or CPU)\n",
    "model = model.to(args.device)\n",
    "\n",
    "# Set the model to evaluation mode.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = ['*.jpeg', '*.jpg', '*.png', '*.JPEG', '*.JPG', '*.PNG']\n",
    "\n",
    "image_files = []\n",
    "for ext in extensions:\n",
    "    # rglob returns a generator, so we extend the list with its results\n",
    "    image_files.extend(VAL_IMAGE_DIR.rglob(ext))\n",
    "\n",
    "print(f'In folder {VAL_IMAGE_DIR}, I found {len(image_files)} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39408937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import requests\n",
    "import json # Don't forget to import json\n",
    "\n",
    "# --- 4. Download and Load the ImageNet Class Index (with caching) ---\n",
    "LABELS_URL = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
    "LABELS_FILE = args.data_cache / 'imagenet_class_index.json' # Local cache file name\n",
    "\n",
    "try:\n",
    "    # Check if we already have the file\n",
    "    if not os.path.exists(LABELS_FILE):\n",
    "        print(f\"Downloading labels to {LABELS_FILE}...\")\n",
    "        response = requests.get(LABELS_URL)\n",
    "        response.raise_for_status()\n",
    "        with open(LABELS_FILE, 'w') as f:\n",
    "            json.dump(response.json(), f)\n",
    "    else:\n",
    "        print(f\"Loading labels from local cache {LABELS_FILE}...\")\n",
    "        \n",
    "    # In both cases, load from the local file\n",
    "    with open(LABELS_FILE, 'r') as f:\n",
    "        class_idx = json.load(f)\n",
    "\n",
    "    # Create a simple mapping from index to class name for easy lookup\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading labels: {e}\")\n",
    "    exit()\n",
    "except (IOError, json.JSONDecodeError) as e:\n",
    "    print(f\"Error handling local label file: {e}\")\n",
    "    exit()\n",
    "idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c48795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Define Image Pre-processing ---\n",
    "# The images must be pre-processed in the exact same way the model was trained on.\n",
    "# This includes resizing, cropping, and normalizing.\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),                # Resize the shortest side to 256px\n",
    "    transforms.CenterCrop(224),            # Crop the center 224x224 pixels\n",
    "    transforms.ToTensor(),                 # Convert the image to a PyTorch Tensor\n",
    "    transforms.Normalize(                  # Normalize with ImageNet mean and std\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15947f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\\nStarting inference on images in '{VAL_IMAGE_DIR}'...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if not image_files:\n",
    "    print(\"No image files found in the specified directory.\")\n",
    "else:\n",
    "    for image_name in image_files:\n",
    "        image_path = os.path.join(VAL_IMAGE_DIR, image_name)\n",
    "\n",
    "        try:\n",
    "            # Load the image\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "\n",
    "            # Pre-process the image and add a batch dimension\n",
    "            # PyTorch models expect a batch of images, so we unsqueeze a dimension.\n",
    "            img_t = preprocess(img)\n",
    "            batch_t = torch.unsqueeze(img_t, 0).to(args.device)\n",
    "\n",
    "            # Run inference\n",
    "            # `torch.no_grad()` tells PyTorch not to compute gradients, saving memory and computation\n",
    "            with torch.no_grad():\n",
    "                output = model(batch_t)\n",
    "\n",
    "            # --- Get the Prediction ---\n",
    "            # The output is a tensor of logits. We find the index of the highest logit.\n",
    "            # `torch.max` returns the max value and its index. We only need the index.\n",
    "            _, index = torch.max(output, 1)\n",
    "            \n",
    "            # Move the result to CPU and convert it to a Python integer\n",
    "            predicted_index = index[0].item()\n",
    "            \n",
    "            # Get the human-readable label from our mapping\n",
    "            predicted_label = idx2label[predicted_index]\n",
    "\n",
    "            # --- Print the result ---\n",
    "            print(f\"Image: {image_name:<30} | Predicted: {predicted_label}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process {image_name}: {e}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Inference complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668de82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
