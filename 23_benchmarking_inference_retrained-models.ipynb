{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0de904",
   "metadata": {},
   "source": [
    "Dans ce script, nous allons tester différents modèles de type convolutionnelsur le dataset \n",
    "\n",
    "résultat:\n",
    "* l'utilisation des batchs rend l'inférence globale plus rapide\n",
    "* un modèle a besoin de beaucoup de temps / parametres pour arriver à un certain niveau d'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efdb6e14-6ce3-481d-9afc-61b1cfee1168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:08:14.291712Z",
     "iopub.status.busy": "2025-12-05T08:08:14.291236Z",
     "iopub.status.idle": "2025-12-05T08:08:16.385029Z",
     "shell.execute_reply": "2025-12-05T08:08:16.384617Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome on macOS-26.1-arm64-arm-64bit-Mach-O\t- Timestamp (UTC)  2025-12-05_08-08-15\t user laurentperrinet\tRunning on MPS device (Apple Silicon/MacOS)\t - macos_version = 26.1\t with device mps, pytorch==2.9.1\n",
      "Random seed 2018 has been set.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Params.__init__() got an unexpected keyword argument 'n_val_stop'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mretinoto_py\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mfovea\u001b[39;00m\n\u001b[32m      2\u001b[39m n_val_stop = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m args = \u001b[43mfovea\u001b[49m\u001b[43m.\u001b[49m\u001b[43mParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_val_stop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_val_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m args\n",
      "\u001b[31mTypeError\u001b[39m: Params.__init__() got an unexpected keyword argument 'n_val_stop'"
     ]
    }
   ],
   "source": [
    "import retinoto_py as fovea\n",
    "n_val_stop = 0\n",
    "args = fovea.Params(n_val_stop=n_val_stop, in_memory=False, verbose=False)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceaab369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:08:16.386305Z",
     "iopub.status.busy": "2025-12-05T08:08:16.386207Z",
     "iopub.status.idle": "2025-12-05T08:08:16.398422Z",
     "shell.execute_reply": "2025-12-05T08:08:16.397976Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model_name = \u001b[43margs\u001b[49m.model_name\n\u001b[32m      2\u001b[39m model_name\n",
      "\u001b[31mNameError\u001b[39m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = args.model_name\n",
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906f00e",
   "metadata": {},
   "source": [
    "# testing different networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e5bc5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:08:16.399607Z",
     "iopub.status.busy": "2025-12-05T08:08:16.399528Z",
     "iopub.status.idle": "2025-12-05T08:08:16.418262Z",
     "shell.execute_reply": "2025-12-05T08:08:16.417887Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m json_filename = \u001b[43margs\u001b[49m.data_cache / \u001b[33m'\u001b[39m\u001b[33m23_benchmarking_inference_retrained-models.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# %rm {json_filename}  # FORCING RECOMPUTE\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m json_filename.exists():\n",
      "\u001b[31mNameError\u001b[39m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "json_filename = args.data_cache / '23_benchmarking_inference_retrained-models.json'\n",
    "\n",
    "# %rm {json_filename}  # FORCING RECOMPUTE\n",
    "\n",
    "if json_filename.exists():\n",
    "    results = fovea.pd.read_json(json_filename)\n",
    "else:\n",
    "    all_results = []\n",
    "    for do_mask in [True, False]:\n",
    "        # for dataset in ['full']:# <HACK until bbox is finished> fovea.all_datasets:\n",
    "        \n",
    "        for dataset in ['bbox']: # fovea.all_datasets:\n",
    "            args = fovea.Params(do_mask=do_mask, n_val_stop=n_val_stop, in_memory=False)\n",
    "            VAL_DATA_DIR = args.DATAROOT / f'Imagenet_{dataset}' / 'val'\n",
    "            val_dataset = fovea.get_dataset(args, VAL_DATA_DIR, n_stop=args.n_val_stop)\n",
    "            val_loader = fovea.get_loader(args, val_dataset)\n",
    "            model_filename = args.data_cache / f'20_model_name={model_name}_dataset={dataset}.pth'\n",
    "            model = fovea.load_model(args, model_filename=model_filename)\n",
    "            param_stats = fovea.count_parameters(model)\n",
    "            total_layers = fovea.count_layers(model)\n",
    "            tic = fovea.time.time()\n",
    "            accuracy = fovea.get_validation_accuracy(args, model, val_loader, f\"Model {model_name}\\t dataset: {dataset}\\t(do_mask={do_mask})\")            \n",
    "            toc = fovea.time.time()\n",
    "            this_result = { 'model_name': model_name,\n",
    "                            'do_mask': do_mask,\n",
    "                            'dataset': dataset,\n",
    "                            'accuracy': accuracy,\n",
    "                            'wall_clock_time': (toc-tic)/len(val_dataset),\n",
    "                            'total_parameters': param_stats['total_parameters'],\n",
    "                            'trainable_parameters': param_stats['trainable_parameters'],\n",
    "                            'total_layers': total_layers}\n",
    "            all_results.append(this_result)\n",
    "    results = fovea.pd.DataFrame(all_results)\n",
    "    results.to_json(json_filename, orient='records', indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9ef69c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:08:16.419427Z",
     "iopub.status.busy": "2025-12-05T08:08:16.419348Z",
     "iopub.status.idle": "2025-12-05T08:08:16.431096Z",
     "shell.execute_reply": "2025-12-05T08:08:16.430772Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresults\u001b[49m.T\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf592ebb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T08:08:16.432415Z",
     "iopub.status.busy": "2025-12-05T08:08:16.432335Z",
     "iopub.status.idle": "2025-12-05T08:08:16.466910Z",
     "shell.execute_reply": "2025-12-05T08:08:16.466570Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Line2D\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Sort results by accuracy within each group to connect points with lines\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m results_sorted = \u001b[43mresults\u001b[49m.sort_values([\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdo_mask\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Define line styles based on do_mask\u001b[39;00m\n\u001b[32m      7\u001b[39m linestyles = {\u001b[38;5;28;01mTrue\u001b[39;00m: \u001b[33m'\u001b[39m\u001b[33m--\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m: \u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m}\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Sort results by accuracy within each group to connect points with lines\n",
    "results_sorted = results.sort_values(['dataset', 'do_mask', 'accuracy'])\n",
    "\n",
    "# Define line styles based on do_mask\n",
    "linestyles = {True: '--', False: '-'}\n",
    "\n",
    "# Define markers for different models\n",
    "markers = {model_name: marker for model_name, marker in \n",
    "           zip(fovea.all_model_names, ['o', 's', '^', 'D', 'v', 'p', '*', 'H'][:len(fovea.all_model_names)])}\n",
    "\n",
    "# Create figure with 2 subplots\n",
    "fig, axes = fovea.plt.subplots(1, 2)\n",
    "\n",
    "# Define color palette for datasets\n",
    "palette = fovea.sns.color_palette(\"husl\", len(fovea.all_datasets))\n",
    "dataset_colors = {dataset: palette[i] for i, dataset in enumerate(fovea.all_datasets)}\n",
    "\n",
    "# Plot 1: Wall clock time vs Accuracy\n",
    "ax = axes[0]\n",
    "for dataset in fovea.all_datasets:\n",
    "    for do_mask in [False, True]:\n",
    "        # Get all data for this dataset/do_mask combination, ordered by model_name order\n",
    "        data_subset = results_sorted[\n",
    "            (results_sorted['dataset'] == dataset) & \n",
    "            (results_sorted['do_mask'] == do_mask)\n",
    "        ].copy()\n",
    "        # Preserve the order of fovea.all_model_names\n",
    "        data_subset['model_name'] = data_subset['model_name'].astype('category')\n",
    "        data_subset['model_name'] = data_subset['model_name'].cat.set_categories(fovea.all_model_names)\n",
    "        data_subset = data_subset.sort_values('model_name')\n",
    "        \n",
    "        if len(data_subset) > 0:\n",
    "            # Plot all models connected by a single line\n",
    "            ax.plot(data_subset['accuracy'], \n",
    "                    data_subset['wall_clock_time'],\n",
    "                    linestyle=linestyles[do_mask],\n",
    "                    color=dataset_colors[dataset],\n",
    "                    linewidth=2.5,\n",
    "                    label=f'{dataset} (mask={do_mask})')\n",
    "            \n",
    "            # Add markers for each model\n",
    "            for model_name in fovea.all_model_names:\n",
    "                model_data = data_subset[data_subset['model_name'] == model_name]\n",
    "                if len(model_data) > 0:\n",
    "                    ax.scatter(model_data['accuracy'], \n",
    "                              model_data['wall_clock_time'],\n",
    "                              marker=markers[model_name],\n",
    "                              color=dataset_colors[dataset],\n",
    "                              s=100,\n",
    "                              zorder=5)\n",
    "\n",
    "ax.set_xlabel('Accuracy', fontsize=12)\n",
    "ax.set_ylabel('Wall Clock Time (s)', fontsize=12)\n",
    "ax.set_title('Inference Time vs Accuracy', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "# ax.legend(fontsize=10, loc='best')\n",
    "\n",
    "# Plot 2: Total parameters vs Accuracy\n",
    "ax = axes[1]\n",
    "for dataset in fovea.all_datasets:\n",
    "    for do_mask in [False, True]:\n",
    "        # Get all data for this dataset/do_mask combination, sorted by model and accuracy\n",
    "        data_subset = results_sorted[\n",
    "            (results_sorted['dataset'] == dataset) & \n",
    "            (results_sorted['do_mask'] == do_mask)\n",
    "        ].copy()\n",
    "        # Preserve the order of fovea.all_model_names\n",
    "        data_subset['model_name'] = data_subset['model_name'].astype('category')\n",
    "        data_subset['model_name'] = data_subset['model_name'].cat.set_categories(fovea.all_model_names)\n",
    "        data_subset = data_subset.sort_values('model_name')\n",
    "        \n",
    "        if len(data_subset) > 0:\n",
    "            # Plot all models connected by a single line\n",
    "            ax.plot(data_subset['accuracy'], \n",
    "                    data_subset['total_parameters'],\n",
    "                    linestyle=linestyles[do_mask],\n",
    "                    color=dataset_colors[dataset],\n",
    "                    linewidth=2.5,\n",
    "                    label=f'{dataset} (mask={do_mask})')\n",
    "            \n",
    "            # Add markers for each model\n",
    "            for model_name in fovea.all_model_names:\n",
    "                model_data = data_subset[data_subset['model_name'] == model_name]\n",
    "                if len(model_data) > 0:\n",
    "                    ax.scatter(model_data['accuracy'], \n",
    "                              model_data['total_parameters'],\n",
    "                              marker=markers[model_name],\n",
    "                              color=dataset_colors[dataset],\n",
    "                              s=100,\n",
    "                              zorder=5)\n",
    "\n",
    "ax.set_xlabel('Accuracy', fontsize=12)\n",
    "ax.set_ylabel('Total Parameters', fontsize=12)\n",
    "ax.set_title('Model Size vs Accuracy', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "# ax.legend(fontsize=10, loc='best')\n",
    "\n",
    "# Create custom legend\n",
    "legend_elements = []\n",
    "\n",
    "# Add dataset colors\n",
    "legend_elements.append(Line2D([0], [0], color='none', label='Datasets:', lw=0))\n",
    "for dataset in fovea.all_datasets:\n",
    "    legend_elements.append(Line2D([0], [0], color=dataset_colors[dataset], lw=2.5, label=f'  {dataset}'))\n",
    "\n",
    "legend_elements.append(Line2D([0], [0], color='none', label='', lw=0))  # Spacer\n",
    "\n",
    "# Add line styles\n",
    "legend_elements.append(Line2D([0], [0], color='none', label='Masking:', lw=0))\n",
    "legend_elements.append(Line2D([0], [0], color='black', linestyle='-', lw=2.5, label='  do_mask=False'))\n",
    "legend_elements.append(Line2D([0], [0], color='black', linestyle='--', lw=2.5, label='  do_mask=True'))\n",
    "\n",
    "legend_elements.append(Line2D([0], [0], color='none', label='', lw=0))  # Spacer\n",
    "\n",
    "# Add models with markers\n",
    "legend_elements.append(Line2D([0], [0], color='none', label='Models:', lw=0))\n",
    "for model_name in fovea.all_model_names:\n",
    "    legend_elements.append(Line2D([0], [0], marker=markers[model_name], color='black', \n",
    "                                      linestyle='none', markersize=8, label=f'  {model_name}'))\n",
    "\n",
    "# Add legend to figure\n",
    "fig.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1.02, 0.5), fontsize=10)\n",
    "\n",
    "fovea.plt.tight_layout()\n",
    "fovea.plt.subplots_adjust(right=1.)\n",
    "fovea.savefig(fig, name='23_benchmarking_inference_retrained-models', figures_folder=args.figures_folder, exts=['pdf'])    \n",
    "fovea.plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
