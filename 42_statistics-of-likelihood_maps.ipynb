{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce09631-1c66-4af0-b7fa-08e78d32a471",
   "metadata": {},
   "source": [
    "Building likelihood maps for a set of representative images.\n",
    "\n",
    "> TODO: use images from dataset and superimpose the bounding boxes on them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8130a92-df14-4988-a525-d2f2d9f68f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T10:47:36.443632Z",
     "iopub.status.busy": "2025-04-26T10:47:36.443348Z",
     "iopub.status.idle": "2025-04-26T10:47:48.382344Z",
     "shell.execute_reply": "2025-04-26T10:47:48.381669Z"
    }
   },
   "outputs": [],
   "source": [
    "import retinoto_py as fovea\n",
    "subset_factor = 5\n",
    "args = fovea.Params(do_fovea=True, batch_size=1, subset_factor=subset_factor)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81dd6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'bbox'\n",
    "VAL_DATA_DIR = args.DATAROOT / f'Imagenet_{dataset}' / 'val'\n",
    "val_dataset = fovea.get_dataset(args, VAL_DATA_DIR, do_full_preprocess=False)\n",
    "val_loader = fovea.get_loader(args, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78542aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = args.data_cache /  f'32_fovea_model_name={args.model_name}_dataset={dataset}.pth'\n",
    "model = fovea.load_model(args, model_filename=model_filename)\n",
    "model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72763425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms import v2 as transforms\n",
    "npy_filename_label = args.data_cache / '42_likelihood_maps_label.npy'\n",
    "npy_filename_max = args.data_cache / '42_likelihood_maps_max.npy'\n",
    "\n",
    "# %rm {npy_filename}  # FORCING RECOMPUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ab141",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = (100, 100)\n",
    "resolution = (30, 30)\n",
    "resolution = (21, 21)\n",
    "size_ratio = .4\n",
    "\n",
    "if npy_filename_label.exists():\n",
    "    likelihood_maps_label = fovea.np.load(npy_filename_label)\n",
    "    likelihood_maps_max = fovea.np.load(npy_filename_max)\n",
    "else:\n",
    "    n_dataset = len(val_dataset)\n",
    "    with fovea.torch.no_grad():\n",
    "        likelihood_maps_label = fovea.np.empty((resolution[0], resolution[1], n_dataset))\n",
    "        likelihood_maps_max = fovea.np.empty((resolution[0], resolution[1], n_dataset))\n",
    "        for i_batch, (image, true_idx) in fovea.tqdm(enumerate(val_loader), total=n_dataset):\n",
    "            image, true_idx = image.to(args.device), true_idx.to(args.device)\n",
    "            pos_H, pos_W = fovea.get_positions(image.shape[1], image.shape[2], resolution=resolution)\n",
    "            probas = fovea.compute_likelihood_map(args, model, image.squeeze(0), pos_H, pos_W, size_ratio=size_ratio)\n",
    "            likelihood_maps_label[:, :, i_batch] = probas[:, true_idx].cpu().numpy().reshape(resolution)\n",
    "            proba_max, _ = probas.max(axis=-1)\n",
    "            likelihood_maps_max[:, :, i_batch] = proba_max.cpu().numpy().reshape(resolution)\n",
    "        fovea.np.save(npy_filename_label, likelihood_maps_label)        \n",
    "        fovea.np.save(npy_filename_max, likelihood_maps_max)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = fovea.plt.subplots()\n",
    "# contour = ax.contourf(likelihood_maps.mean(axis=-1))\n",
    "# fig.colorbar(contour, ax=ax)  # Add colorbar\n",
    "# ax.axis('square')\n",
    "# fig.set_facecolor(color='white')\n",
    "likelihood_maps = likelihood_maps_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas.max(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c41f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_image = 2\n",
    "proba = likelihood_maps[:, :, i_image]\n",
    "proba.min(), proba.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fed851",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = fovea.plt.subplots()\n",
    "contour = ax.contourf(likelihood_maps.mean(axis=-1))\n",
    "fig.colorbar(contour, ax=ax)  # Add colorbar\n",
    "ax.axis('square')\n",
    "fig.set_facecolor(color='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = likelihood_maps.max(axis=(0, 1))\n",
    "fig, ax = fovea.plt.subplots()\n",
    "ax.hist(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pos_H, pos_W = fovea.get_positions(1, 1, resolution=resolution)\n",
    "pos_H.min(), pos_H.max(), pos_W.min(), pos_W.max(), pos_H.shape, likelihood_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22303241",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for do_fovea in [True, False]:    \n",
    "    likelihood_maps = fovea.np.load(npy_filename)\n",
    "    data_= pd.DataFrame({\n",
    "        'horizontal position': pos_H,\n",
    "        'vertical position': pos_W,\n",
    "        'probas': likelihood_maps.mean(axis=-1).T.flatten(),\n",
    "        'retinotopy': 'foveated' if do_fovea else 'uniform' \n",
    "    })\n",
    "    data.append(data_)\n",
    "combined_data = pd.concat(data, ignore_index=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def visualize_likelihood_map(likelihood_map, sigma=0, color='blue', fig=None, axes=None):\n",
    "    # Lisser la heatmap\n",
    "    if sigma >0: likelihood_map = gaussian_filter(likelihood_map, sigma=sigma)\n",
    "\n",
    "    # Calcul des marginales\n",
    "    marginal_H = likelihood_map.mean(axis=1)  # Marginale verticale\n",
    "    marginal_W = likelihood_map.mean(axis=0)  # Marginale horizontale\n",
    "\n",
    "    # Créer la figure et l'axe principal\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Afficher la heatmap\n",
    "    contour = ax.contourf(likelihood_map, levels=20, cmap=\"viridis\")\n",
    "    fig.colorbar(contour, ax=ax, label='Likelihood')\n",
    "    # ax.set_title(\"Carte de probabilité de vraisemblance\")\n",
    "    ax.set_xlabel(\"Position (W)\")\n",
    "    ax.set_ylabel(\"Position (H)\")\n",
    "\n",
    "    # Ajouter une grille légère\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Ajouter les lignes centrales (verticale et horizontale)\n",
    "    mid_w = likelihood_map.shape[1] / 2\n",
    "    mid_h = likelihood_map.shape[0] / 2\n",
    "    ax.axvline(x=mid_w, color='white', linestyle='--', linewidth=2)\n",
    "    ax.axhline(y=mid_h, color='white', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Ajouter des axes pour les marginales\n",
    "    divider = make_axes_locatable(ax)\n",
    "\n",
    "    # Axe pour la marginale horizontale (en haut)\n",
    "    ax_top = divider.append_axes(\"top\", 1.2, pad=0.1, sharex=ax)\n",
    "    # ax_top.plot(np.linspace(-1, 1, resolution[1]), marginal_W, color='red')\n",
    "    ax_top.plot(range(resolution[1]), marginal_W, color=color)\n",
    "    # ax_top.set_title(\"Probabilité marginale (axe horizontal)\")\n",
    "    # ax_top.set_ylabel(\"Probabilité\")\n",
    "    ax_top.set_xticks([])  # Pas de labels sur l'axe x pour éviter la redondance\n",
    "\n",
    "    # Axe pour la marginale verticale (à droite)\n",
    "    ax_right = divider.append_axes(\"right\", 1.2, pad=0.1, sharey=ax)\n",
    "    # ax_right.plot(marginal_H, np.linspace(-1, 1, resolution[0]), color='blue')\n",
    "    ax_right.plot(marginal_H, range(resolution[0]), color=color)\n",
    "    # ax_right.set_title(\"Probabilité marginale (axe vertical)\")\n",
    "    # ax_right.set_xlabel(\"Probabilité\")\n",
    "    ax_right.set_yticks([])  # Pas de labels sur l'axe y pour éviter la redondance\n",
    "\n",
    "    plt.tight_layout()\n",
    "    axes = (ax, ax_top, ax_right)\n",
    "    return fig, axes\n",
    "\n",
    "fig, axes = visualize_likelihood_map(likelihood_maps.mean(axis=-1))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i_image in [42, 23, 57]:\n",
    "    fig, axes = visualize_likelihood_map(likelihood_maps[:, :, i_image], sigma=.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def gaussian_2d(x, y, amplitude, x0, y0, sigma_x, sigma_y, theta):\n",
    "    \"\"\"\n",
    "    2D Gaussian function with rotation (theta).\n",
    "    \"\"\"\n",
    "    a = (np.cos(theta)**2)/(2*sigma_x**2) + (np.sin(theta)**2)/(2*sigma_y**2)\n",
    "    b = -(np.sin(2*theta))/(4*sigma_x**2) + (np.sin(2*theta))/(4*sigma_y**2)\n",
    "    c = (np.sin(theta)**2)/(2*sigma_x**2) + (np.cos(theta)**2)/(2*sigma_y**2)\n",
    "    return amplitude * np.exp(-(a*((x-x0)**2) + 2*b*(x-x0)*(y-y0) + c*((y-y0)**2)))\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def fit_gaussian(likelihood_map):\n",
    "    \"\"\"\n",
    "    Fit a 2D Gaussian to a likelihood map, constraining x0 and y0 to [-1, 1].\n",
    "    Returns: amplitude, x0, y0, sigma_x, sigma_y, theta (rotation angle)\n",
    "    \"\"\"\n",
    "    # Create a grid of coordinates\n",
    "    ny, nx = likelihood_map.shape\n",
    "    x = np.linspace(-1, 1, nx)\n",
    "    y = np.linspace(-1, 1, ny)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "\n",
    "    # Flatten the likelihood map and coordinates\n",
    "    data = likelihood_map.flatten()\n",
    "    x_flat = x.flatten()\n",
    "    y_flat = y.flatten()\n",
    "\n",
    "    # Initial guess for parameters\n",
    "    initial_guess = (\n",
    "        np.max(likelihood_map),  # amplitude\n",
    "        0,                       # x0 (middle of the map)\n",
    "        0,                       # y0\n",
    "        0.9,                     # sigma_x\n",
    "        0.9,                     # sigma_y\n",
    "        0                        # theta (no rotation)\n",
    "    )\n",
    "\n",
    "    # Define bounds: (x0, y0) must be in [-1, 1]\n",
    "    # Format: ([min_amp, min_x0, min_y0, min_sx, min_sy, min_theta], [max_amp, max_x0, max_y0, max_sx, max_sy, max_theta])\n",
    "    bounds = (\n",
    "        [-np.inf, -1, -1, 0.01, 0.01, -np.pi],  # Lower bounds\n",
    "        [np.inf, 1, 1, 2, 2, np.pi]            # Upper bounds\n",
    "    )\n",
    "\n",
    "    # Fit the Gaussian with bounds\n",
    "    try:\n",
    "        popt, pcov = curve_fit(\n",
    "            lambda arr, amp, x0, y0, sx, sy, theta:\n",
    "                gaussian_2d(arr[0], arr[1], amp, x0, y0, sx, sy, theta),\n",
    "            (x_flat, y_flat),\n",
    "            data,\n",
    "            p0=initial_guess,\n",
    "            bounds=bounds,\n",
    "            maxfev=100000\n",
    "        )\n",
    "        return popt\n",
    "    except RuntimeError:\n",
    "        # If fitting fails, return NaN values\n",
    "        return np.full(6, np.nan)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def compute_gaussian_params(likelihood_maps):\n",
    "    \"\"\"\n",
    "    Compute Gaussian parameters for each likelihood map in `likelihood_maps`.\n",
    "    `likelihood_maps` shape: (height, width, n_images)\n",
    "    Returns: pandas DataFrame with columns for each parameter\n",
    "    \"\"\"\n",
    "    n_images = likelihood_maps.shape[-1]\n",
    "    results = {\n",
    "        'image_index': [],\n",
    "        'amplitude': [],\n",
    "        'x0': [],\n",
    "        'y0': [],\n",
    "        'sigma_x': [],\n",
    "        'sigma_y': [],\n",
    "        'theta': []\n",
    "    }\n",
    "\n",
    "    for i_image in fovea.tqdm(range(n_images)):\n",
    "        likelihood_map = likelihood_maps[:, :, i_image]\n",
    "        # Smooth the map to reduce noise\n",
    "        likelihood_map = gaussian_filter(likelihood_map, sigma=1)\n",
    "        # Fit the Gaussian\n",
    "        gaussian_params = fit_gaussian(likelihood_map)\n",
    "\n",
    "        # Append results to the dictionary\n",
    "        results['image_index'].append(i_image)\n",
    "        results['amplitude'].append(gaussian_params[0])\n",
    "        results['x0'].append(gaussian_params[1])\n",
    "        results['y0'].append(gaussian_params[2])\n",
    "        results['sigma_x'].append(gaussian_params[3])\n",
    "        results['sigma_y'].append(gaussian_params[4])\n",
    "        results['theta'].append(gaussian_params[5])\n",
    "\n",
    "    # Convert the dictionary to a pandas DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "gaussian_df = compute_gaussian_params(likelihood_maps)\n",
    "gaussian_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9957493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint KDE plot with marginals\n",
    "g = sns.jointplot(\n",
    "    data=gaussian_df,\n",
    "    x=\"x0\",\n",
    "    y=\"y0\",\n",
    "    kind=\"kde\",\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Check if sigma_x is usually bigger than sigma_y\n",
    "is_sigma_x_bigger = gaussian_df[\"sigma_x\"] > gaussian_df[\"sigma_y\"]\n",
    "print(f\"Fraction of images where sigma_x > sigma_y (more horizontal): {is_sigma_x_bigger.mean():.2f}\")\n",
    "print(f\"Fraction of images where sigma_y > sigma_x (more vertical): {(~is_sigma_x_bigger).mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80033be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lmfit\n",
    "from lmfit import Parameters, minimize, report_fit\n",
    "\n",
    "def gaussian_2d_lmfit(params, x, y, data):\n",
    "    \"\"\"\n",
    "    2D Gaussian function for lmfit.\n",
    "    \"\"\"\n",
    "    amp = params['amplitude']\n",
    "    x0 = params['x0']\n",
    "    y0 = params['y0']\n",
    "    sx = params['sigma_x']\n",
    "    sy = params['sigma_y']\n",
    "    theta = params['theta']\n",
    "\n",
    "    a = (np.cos(theta)**2)/(2*sx**2) + (np.sin(theta)**2)/(2*sy**2)\n",
    "    b = -(np.sin(2*theta))/(4*sx**2) + (np.sin(2*theta))/(4*sy**2)\n",
    "    c = (np.sin(theta)**2)/(2*sx**2) + (np.cos(theta)**2)/(2*sy**2)\n",
    "\n",
    "    model = amp * np.exp(-(a*((x-x0)**2) + 2*b*(x-x0)*(y-y0) + c*((y-y0)**2)))\n",
    "    return model - data  # Residuals for least-squares minimization\n",
    "\n",
    "def fit_gaussian_lmfit(likelihood_map):\n",
    "    \"\"\"\n",
    "    Fit a 2D Gaussian to a likelihood map using lmfit, constraining x0 and y0 to [-1, 1].\n",
    "    Returns: amplitude, x0, y0, sigma_x, sigma_y, theta (rotation angle)\n",
    "    \"\"\"\n",
    "    # Create a grid of coordinates\n",
    "    ny, nx = likelihood_map.shape\n",
    "    x = np.linspace(-1, 1, nx)\n",
    "    y = np.linspace(-1, 1, ny)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "\n",
    "    # Flatten the likelihood map and coordinates\n",
    "    data = likelihood_map.flatten()\n",
    "    x_flat = x.flatten()\n",
    "    y_flat = y.flatten()\n",
    "\n",
    "    # Create Parameters object with initial guesses and bounds\n",
    "    params = lmfit.Parameters()\n",
    "    params.add('amplitude', value=np.max(likelihood_map), min=0)  # Amplitude must be positive\n",
    "    params.add('x0', value=0, min=-1, max=1)  # x0 in [-1, 1]\n",
    "    params.add('y0', value=0, min=-1, max=1)  # y0 in [-1, 1]\n",
    "    params.add('sigma_x', value=0.5, min=0.01, max=4)  # sigma_x bounds\n",
    "    params.add('sigma_y', value=0.5, min=0.01, max=4)  # sigma_y bounds\n",
    "    params.add('theta', value=0, min=-np.pi/2, max=np.pi/2)  # theta bounds\n",
    "\n",
    "    # Minimize the residuals using least-squares\n",
    "    result = minimize(\n",
    "        gaussian_2d_lmfit,\n",
    "        params,\n",
    "        args=(x_flat, y_flat, data),\n",
    "        # method='leastsq',  # Levenberg-Marquardt algorithm\n",
    "        method='lbfgsb',\n",
    "        tol=1e-8,\n",
    "        # xtol=1e-8,\n",
    "        max_nfev=20000\n",
    "    )\n",
    "\n",
    "    # Check if the fit succeeded\n",
    "    if not result.success:\n",
    "        return np.full(6, np.nan)\n",
    "\n",
    "    fit_result = {}\n",
    "    for name, param in result.params.items():\n",
    "        fit_result[name] = param.value\n",
    "        # fit_result[f\"{name}_error\"] = param.stderr\n",
    "\n",
    "    return fit_result\n",
    "\n",
    "\n",
    "def compute_gaussian_params(likelihood_maps, sigma=.5):\n",
    "    \"\"\"\n",
    "    Compute Gaussian parameters for each likelihood map in `likelihood_maps`.\n",
    "    `likelihood_maps` shape: (height, width, n_images)\n",
    "    Returns: pandas DataFrame with columns for each parameter\n",
    "    \"\"\"\n",
    "    n_images = likelihood_maps.shape[-1]\n",
    "    results = []\n",
    "\n",
    "    for i_image in fovea.tqdm(range(n_images)):\n",
    "        likelihood_map = likelihood_maps[:, :, i_image]\n",
    "        # Smooth the map to reduce noise\n",
    "        likelihood_map = gaussian_filter(likelihood_map, sigma=sigma)\n",
    "        # Fit the Gaussian\n",
    "        results.append(fit_gaussian_lmfit(likelihood_map))\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a pandas DataFrame\n",
    "    gaussian_df = pd.DataFrame(results)\n",
    "    gaussian_df[\"theta_deg\"] = np.rad2deg(gaussian_df[\"theta\"])\n",
    "    gaussian_df['sigma_major'] = np.where(gaussian_df['sigma_x'] > gaussian_df['sigma_y'], \n",
    "                                          gaussian_df['sigma_x'], gaussian_df['sigma_y'])\n",
    "    gaussian_df['sigma_minor'] = np.where(gaussian_df['sigma_x'] < gaussian_df['sigma_y'], \n",
    "                                          gaussian_df['sigma_x'], gaussian_df['sigma_y'])\n",
    "\n",
    "    gaussian_df[\"elongation\"] = gaussian_df['sigma_major'] / gaussian_df['sigma_minor']\n",
    "    return gaussian_df\n",
    "gaussian_df = compute_gaussian_params(likelihood_maps, sigma=.5)\n",
    "gaussian_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02abdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint KDE plot with marginals\n",
    "g = sns.jointplot(\n",
    "    data=gaussian_df,\n",
    "    x=\"x0\",\n",
    "    y=\"y0\",\n",
    "    kind=\"kde\",\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint KDE plot with marginals\n",
    "g = sns.jointplot(\n",
    "    data=gaussian_df,\n",
    "    x=\"sigma_x\",\n",
    "    y=\"sigma_y\",\n",
    "    kind=\"scatter\",\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8124abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint KDE plot with marginals\n",
    "g = sns.jointplot(\n",
    "    data=gaussian_df,\n",
    "    x=\"sigma_minor\",\n",
    "    y=\"sigma_major\",\n",
    "    kind=\"scatter\",\n",
    "    alpha=.2,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=gaussian_df,\n",
    "    x='elongation',\n",
    "    bins=40,\n",
    "    element='step',  # Use step plots for clarity\n",
    "    kde=False,  # Disable KDE for log-scaled x-axis\n",
    "    color='skyblue',\n",
    "    alpha=0.7,\n",
    "    edgecolor='black',\n",
    "    log_scale=(True, False)  # Log scale only for the x-axis\n",
    ")\n",
    "\n",
    "# Compute the peak (bin with the highest count)\n",
    "counts, bin_edges = np.histogram(np.log(gaussian_df['elongation']), bins=40)\n",
    "peak_bin_index = np.argmax(counts)\n",
    "log_peak_value = (bin_edges[peak_bin_index] + bin_edges[peak_bin_index + 1]) / 2  # Midpoint of the peak bin\n",
    "peak_count = counts[peak_bin_index]\n",
    "peak_value = np.exp(log_peak_value)\n",
    "\n",
    "# Annotate the peak on the plot\n",
    "plt.axvline(x=peak_value, color='red', linestyle='--', label=f'Peak: {peak_value:.2f}')\n",
    "plt.text(\n",
    "    4,\n",
    "    120,\n",
    "    f' Peak @ {peak_value:.2f}',\n",
    "    ha='center',\n",
    "    va='bottom',\n",
    "    color='red',\n",
    "    fontsize=24,\n",
    "    bbox=dict(facecolor='white', alpha=0., edgecolor='none')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_df['elongation'].min(), gaussian_df['elongation'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa9a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de95b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=gaussian_df,\n",
    "    x='theta_deg',\n",
    "    bins=30,\n",
    "    element='step'  # Use step plots for clarity\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90137a",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "* θ=0: The major axis is aligned with the x-axis.\n",
    "* θ=π/2: The major axis is aligned with the y-axis.\n",
    "* θ=π/4: The major axis is at a 45° angle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b0521b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
