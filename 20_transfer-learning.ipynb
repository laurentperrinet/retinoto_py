{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0de904",
   "metadata": {},
   "source": [
    "Dans ce script, nous allons tester différents modèles de type convolution Nelle pour examiner leur performance. Nous allons ensuite tester s'ils sont robustes lorsqu'on applique une rotation à l'image d'entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb6e14-6ce3-481d-9afc-61b1cfee1168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T10:45:23.376798Z",
     "iopub.status.busy": "2025-04-26T10:45:23.376511Z",
     "iopub.status.idle": "2025-04-26T10:45:36.118070Z",
     "shell.execute_reply": "2025-04-26T10:45:36.117553Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import retinoto_py as fovea\n",
    "\n",
    "args = fovea.Params(batch_size=1)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f4302",
   "metadata": {},
   "source": [
    "# testing each network on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dataset = 'Imagenet_bbox'\n",
    "dataset = 'Imagenet_full'\n",
    "TRAIN_DATA_DIR = args.DATAROOT / dataset / 'train'\n",
    "VAL_DATA_DIR = args.DATAROOT / dataset / 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15947f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinoto_py import get_loader\n",
    "train_loader, class_to_idx, idx_to_class = get_loader(args, TRAIN_DATA_DIR)\n",
    "val_loader, class_to_idx, idx_to_class = get_loader(args, VAL_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06229308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 1000 output features to final FC layer for 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Load the Pre-trained ResNet Model ---\n",
    "from retinoto_py import load_model, count_parameters, count_layers\n",
    "model = load_model(args)\n",
    "\n",
    "# Make sure to load a model trained on the same number of classes\n",
    "num_classes = len(val_loader.dataset.classes)\n",
    "num_ftrs = model.fc.out_features\n",
    "print(f'Model has {num_ftrs} output features to final FC layer for {num_classes} classes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd176b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "Training model resnet18, file= cached_data/20_resnet18_retrained.pth - image_size=224\n",
      "Starting learning...\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 1 : train= loss: 3.0456 / acc : 3.0456 - val= loss : 365334683830765120.0000 / acc : 0.0010 / time:553.1\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 20019 : train= loss: 38832196494327971840.0000 / acc : 38832196494327971840.0000 - val= loss : 7.4910 / acc : 0.0010 / time:1592.7\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 40037 : train= loss: 82.4446 / acc : 82.4446 - val= loss : 7.5063 / acc : 0.0010 / time:2622.5\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 60055 : train= loss: 3.7537 / acc : 3.7537 - val= loss : 7.5175 / acc : 0.0010 / time:3647.5\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 80073 : train= loss: 3.7522 / acc : 3.7522 - val= loss : 7.4779 / acc : 0.0010 / time:4673.3\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 100091 : train= loss: 3.7534 / acc : 3.7534 - val= loss : 7.4884 / acc : 0.0010 / time:5709.8\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 120109 : train= loss: 3.7501 / acc : 3.7501 - val= loss : 7.5322 / acc : 0.0010 / time:6740.7\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 140127 : train= loss: 3.7539 / acc : 3.7539 - val= loss : 7.5403 / acc : 0.0010 / time:7765.4\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 160145 : train= loss: 3.7530 / acc : 3.7530 - val= loss : 7.5078 / acc : 0.0010 / time:8795.0\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 180163 : train= loss: 3.7506 / acc : 3.7506 - val= loss : 7.5112 / acc : 0.0010 / time:9828.9\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 200181 : train= loss: 3.7531 / acc : 3.7531 - val= loss : 7.5294 / acc : 0.0010 / time:10853.4\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 220199 : train= loss: 3.7540 / acc : 3.7540 - val= loss : 7.4832 / acc : 0.0010 / time:11879.2\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 240217 : train= loss: 3.7513 / acc : 3.7513 - val= loss : 7.5059 / acc : 0.0010 / time:12918.4\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 260235 : train= loss: 3.7509 / acc : 3.7509 - val= loss : 7.5041 / acc : 0.0010 / time:13947.9\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 280253 : train= loss: 3.7537 / acc : 3.7537 - val= loss : 7.5174 / acc : 0.0010 / time:14974.2\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 300271 : train= loss: 3.7487 / acc : 3.7487 - val= loss : 7.5374 / acc : 0.0010 / time:16007.7\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 320289 : train= loss: 3.7518 / acc : 3.7518 - val= loss : 7.4918 / acc : 0.0010 / time:17036.6\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 340307 : train= loss: 3.7553 / acc : 3.7553 - val= loss : 7.4815 / acc : 0.0010 / time:18062.3\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 360325 : train= loss: 3.7536 / acc : 3.7536 - val= loss : 7.4894 / acc : 0.0010 / time:19088.5\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 380343 : train= loss: 3.7558 / acc : 3.7558 - val= loss : 7.4853 / acc : 0.0010 / time:20129.7\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 400361 : train= loss: 3.7548 / acc : 3.7548 - val= loss : 7.5038 / acc : 0.0010 / time:21159.9\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 420379 : train= loss: 3.7560 / acc : 3.7560 - val= loss : 7.4480 / acc : 0.0010 / time:22187.6\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 440397 : train= loss: 3.7495 / acc : 3.7495 - val= loss : 7.4816 / acc : 0.0010 / time:23221.6\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 460415 : train= loss: 3.7527 / acc : 3.7527 - val= loss : 7.4737 / acc : 0.0010 / time:24259.0\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 480433 : train= loss: 3.7548 / acc : 3.7548 - val= loss : 7.5107 / acc : 0.0010 / time:25285.2\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 500451 : train= loss: 3.7516 / acc : 3.7516 - val= loss : 7.4890 / acc : 0.0010 / time:26310.5\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 520469 : train= loss: 3.7530 / acc : 3.7530 - val= loss : 7.5170 / acc : 0.0010 / time:27349.0\n",
      "cached_data/20_resnet18_retrained.pth - Epoch 0, i_image 540487 : train= loss: 3.7539 / acc : 3.7539 - val= loss : 7.4948 / acc : 0.0010 / time:28377.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs.model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, file= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - image_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs.image_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m model_retrain, df_train = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m elapsed_time = time.time() - start_time\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;250m \u001b[39m%\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/src/retinoto_py/retinoto_py.py:160\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(args, model, train_loader, val_loader, df_train, each_steps, verbose, do_save, model_filename)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torchvision/models/resnet.py:285\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torchvision/models/resnet.py:273\u001b[39m, in \u001b[36mResNet._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    270\u001b[39m x = \u001b[38;5;28mself\u001b[39m.relu(x)\n\u001b[32m    271\u001b[39m x = \u001b[38;5;28mself\u001b[39m.maxpool(x)\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer2(x)\n\u001b[32m    275\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torchvision/models/resnet.py:93\u001b[39m, in \u001b[36mBasicBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     90\u001b[39m identity = x\n\u001b[32m     92\u001b[39m out = \u001b[38;5;28mself\u001b[39m.conv1(x)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m out = \u001b[38;5;28mself\u001b[39m.relu(out)\n\u001b[32m     96\u001b[39m out = \u001b[38;5;28mself\u001b[39m.conv2(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/science/retinoto_py/.venv/lib/python3.13/site-packages/torch/nn/functional.py:2813\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2810\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2811\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2813\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2814\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2815\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2821\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x741.656 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time \n",
    "from retinoto_py import train_model \n",
    "fig_width, phi = 12, 1.618\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(50*'.')\n",
    "model_filename = args.data_cache / f'20_{args.model_name}_retrained.pth'\n",
    "json_filename = args.data_cache / model_filename.name.replace('.pth', '.json')\n",
    "lock_filename = args.data_cache / model_filename.name.replace('.pth', '.lock')\n",
    "def touch(fname): open(fname, 'w').close()\n",
    "\n",
    "df_train = None\n",
    "should_resume_training = not lock_filename.exists()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(fig_width, fig_width/phi)) #, subplotpars=subplotpars)\n",
    "\n",
    "if json_filename.exists():\n",
    "    print(f\"Load JSON from pre-trained resnet {json_filename}\")\n",
    "    df_train = pd.read_json(json_filename, orient='index')\n",
    "    print(f\"{model_filename}: accuracy = {df_train['avg_acc_val'][-5:].mean():.3f}\")\n",
    "    should_resume_training = (df_train['epoch'].max() + 1 < args.num_epochs) and (not lock_filename.exists())\n",
    "\n",
    "if should_resume_training:\n",
    "    touch(lock_filename) # as we do a training let's lock it\n",
    "    # we need to train the model or finish a training that already started\n",
    "    print(f\"Training model {args.model_name}, file= {model_filename} - image_size={args.image_size}\")\n",
    "    start_time = time.time()\n",
    "    model_retrain, df_train = train_model(args, model=model, train_loader=train_loader, val_loader=val_loader, df_train=df_train, model_filename=model_filename)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "\n",
    "    print()     \n",
    "\n",
    "color = 'r'\n",
    "lw = 1\n",
    "\n",
    "if not(df_train is None):\n",
    "    trained_epochs = df_train['epoch'].max() + 1\n",
    "    if trained_epochs < args.num_epochs:\n",
    "        print(f\"Training in progress with {trained_epochs} \")\n",
    "    else:\n",
    "        if lock_filename.exists(): lock_filename.remove()\n",
    "\n",
    "        x = df_train['total_image'].values\n",
    "        y = df_train['avg_acc_val'].values\n",
    "\n",
    "        df_train_roll = df_train.rolling(window=5, min_periods=1, center=False).mean()\n",
    "        ax = df_train_roll.plot(x='total_image', y='avg_acc', \n",
    "                            c=color, ls='dashed', lw=lw,\n",
    "                            grid=True, ax=ax, label='TRAIN: ' + args.model_name)    \n",
    "        ax = df_train_roll.plot(x='total_image', y='avg_acc_val', \n",
    "                            c=color, lw=lw,\n",
    "                            grid=True, ax=ax, label='VAL: ' + args.model_name)   \n",
    "\n",
    "        # the model has been trained, we can remove the lock file     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e33a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_filename.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm {lock_filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55842ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
