{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85fa0b04",
   "metadata": {},
   "source": [
    "Optimisation de l'entrainement pour `focus` \n",
    "This is the same function as used in `10_Transfer_learning_what_networks.ipynb`\n",
    "> ... TODO ... # TODO test without circular padding, with Adam, with no warmstart \n",
    "\n",
    "    model = torchvision.models.resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c9376",
   "metadata": {},
   "source": [
    "# optimize meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93398977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52de34cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:39:11.636468Z",
     "iopub.status.busy": "2025-04-26T09:39:11.636217Z",
     "iopub.status.idle": "2025-04-26T09:39:11.638525Z",
     "shell.execute_reply": "2025-04-26T09:39:11.638107Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_gpu_memory()\n",
    "\n",
    "# print(path_save)\n",
    "# %ls -l {path}*\n",
    "\n",
    "# %rm \"cached_data/34_optuna.sqlite3\"  # FORCING RECOMPUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32099fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:39:11.640275Z",
     "iopub.status.busy": "2025-04-26T09:39:11.640024Z",
     "iopub.status.idle": "2025-04-26T09:39:11.751525Z",
     "shell.execute_reply": "2025-04-26T09:39:11.751077Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome on macOS-26.1-arm64-arm-64bit-Mach-O\t user laurent\tRunning on MPS device (Apple Silicon/MacOS)\t - macos_version = 26.1\t with device mps, pytorch==2.9.1\n",
      "Random seed 2018 has been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Params(image_size=224, do_mask=False, do_fovea=True, rs_min=0.0, rs_max=-5.0, padding_mode='zeros', seed=2018, batch_size=80, num_workers=4, in_memory=True, model_name='convnext_base', do_scratch=False, num_epochs=1, n_train_stop=81920, n_val_stop=10240, do_full_training=False, lr=5e-06, delta1=0.3, delta2=0.05, weight_decay=0.05, label_smoothing=0.03, shuffle=True, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import retinoto_py as fovea\n",
    "# batch_size = 64\n",
    "# args = fovea.Params()\n",
    "# opts_dict = dict(do_fovea=True, num_epochs=1, verbose=False)\n",
    "# args = dataclasses.replace(args, **opts_dict)\n",
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779982c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params(image_size=224, do_mask=False, do_fovea=True, rs_min=0.0, rs_max=-5.0, padding_mode='zeros', seed=2018, batch_size=80, num_workers=4, in_memory=True, model_name='convnext_base', do_scratch=False, num_epochs=1, n_train_stop=81920, n_val_stop=10240, do_full_training=False, lr=5e-06, delta1=0.3, delta2=0.05, weight_decay=0.05, label_smoothing=0.03, shuffle=True, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import retinoto_py as fovea\n",
    "args = fovea.Params(do_fovea=True, num_epochs=1, verbose=False)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "852159f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 laurent  staff  178843891 27 nov.  09:12 cached_data/32_fovea_model_name=resnet101_dataset=bbox_retrained_bkp.pth\n",
      "-rw-r--r--  1 laurent  staff       2132 27 nov.  09:47 cached_data/32_fovea_model_name=resnet101_dataset=bbox_retrained_bkp.json\n",
      "-rw-r--r--  1 laurent  staff       2140 27 nov.  18:05 cached_data/32_fovea_model_name=resnet101_dataset=full.json\n",
      "-rw-r--r--  1 laurent  staff          0 27 nov.  19:37 cached_data/32_fovea_model_name=resnet101_dataset=full.lock\n",
      "-rw-r--r--  1 laurent  staff  178837571 27 nov.  20:42 cached_data/32_fovea_model_name=resnet101_dataset=full.pth\n",
      "-rw-r--r--  1 laurent  staff          0 27 nov.  23:43 cached_data/32_fovea_model_name=resnet101_dataset=bbox.lock\n",
      "-rw-r--r--  1 laurent  staff  178837571 28 nov.  09:05 cached_data/32_fovea_model_name=resnet101_dataset=bbox.pth\n",
      "-rw-r--r--  1 laurent  staff       1955 28 nov.  09:05 cached_data/32_fovea_model_name=resnet101_dataset=bbox.json\n"
     ]
    }
   ],
   "source": [
    "%ls -ltr cached_data/32*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8167317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_filename = None # do not use resumed net\n",
    "# model_filename = args.data_cache / f'32_fovea_model_name={args.model_name}_dataset={dataset}_retrained_bkp.pth'\n",
    "# model_filename = args.data_cache / f'32_fovea_model_name={args.model_name}_dataset={dataset}.pth'\n",
    "model_filename = args.data_cache / f'33_fovea_model_name={args.model_name}_dataset={dataset}.pth'\n",
    "model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63f937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:39:11.758402Z",
     "iopub.status.busy": "2025-04-26T09:39:11.758023Z",
     "iopub.status.idle": "2025-04-26T09:39:11.763618Z",
     "shell.execute_reply": "2025-04-26T09:39:11.763199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579f920e784f45faa739be02b74776a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Putting images in memory:   0%|          | 0/81920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ac809d715b47c584239aa96425bcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Putting images in memory:   0%|          | 0/10240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 'bbox'\n",
    "TRAIN_DATA_DIR = args.DATAROOT / f'Imagenet_{dataset}' / 'train'\n",
    "train_dataset = fovea.get_dataset(args, TRAIN_DATA_DIR, n_stop=args.n_train_stop)\n",
    "train_loader = fovea.get_loader(args, train_dataset)\n",
    "VAL_DATA_DIR = args.DATAROOT / f'Imagenet_{dataset}' / 'val'\n",
    "val_dataset = fovea.get_dataset(args, VAL_DATA_DIR, n_stop=args.n_val_stop)\n",
    "val_loader = fovea.get_loader(args, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = fovea.get_validation_accuracy(args, args.model_name, val_loader, f\"Evaluating {args.model_name} on dataset: {dataset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25db669a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:39:12.014727Z",
     "iopub.status.busy": "2025-04-26T09:39:12.014406Z",
     "iopub.status.idle": "2025-04-26T09:39:21.669960Z",
     "shell.execute_reply": "2025-04-26T09:39:21.669014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization with params: Params(image_size=224, do_mask=False, do_fovea=True, rs_min=0.0, rs_max=-5.0, padding_mode='zeros', seed=2018, batch_size=80, num_workers=4, in_memory=True, model_name='convnext_base', do_scratch=False, num_epochs=1, n_train_stop=81920, n_val_stop=10240, do_full_training=False, lr=5e-06, delta1=0.3, delta2=0.05, weight_decay=0.05, label_smoothing=0.03, shuffle=True, verbose=False) on 150 trials - 0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebeb0e1e08049c4b27ac187995466f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6bb7d7b9fa45648fb9f7e935ec1faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch=1/1:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7641d6a4a1424f5dabf50d91b54ee3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vat @Epoch 1/1:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3ffe6aedc04029901241910e827788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch=1/1:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ba585b10eb4fe3946cdcfd064eaeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vat @Epoch 1/1:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb07ad5a749484a93eadd12cc6dcef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch=1/1:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-30 08:48:14,321] Trial 2 failed with parameters: {'delta2': 0.021322141202746732, 'lr': 2.3779490212066976e-06, 'delta1': 0.09725729245416023, 'weight_decay': 0.1933949318454619, 'label_smoothing': 0.1342797199548113} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/laurent/app54_nextcloud/science/retinoto_py/.venv/lib/python3.14/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/qt/n82pbkv93fjb7bpt0pj1992w0000gn/T/ipykernel_34468/357449951.py\", line 25, in objective\n",
      "    _, df_train = fovea.train_model(args, model=model, train_loader=train_loader, val_loader=val_loader)\n",
      "                  ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/laurent/app54_nextcloud/science/retinoto_py/src/retinoto_py/retinoto_py.py\", line 156, in train_model\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-30 08:48:14,322] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     31\u001b[39m study = optuna.create_study(storage=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msqlite:///cached_data/34_optuna.sqlite3\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     32\u001b[39m                             sampler=optuna.samplers.TPESampler(multivariate=\u001b[38;5;28;01mFalse\u001b[39;00m, warn_independent_sampling=\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m     33\u001b[39m                             direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m, load_if_exists=\u001b[38;5;28;01mTrue\u001b[39;00m, study_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m34_optuna\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mStarting optimization with params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(\u001b[32m150\u001b[39m-\u001b[38;5;28mlen\u001b[39m(study.trials),\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trials - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(study.trials)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m-\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[32m50\u001b[39m*\u001b[33m'\u001b[39m\u001b[33m-.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params: \u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app54_nextcloud/science/retinoto_py/.venv/lib/python3.14/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app54_nextcloud/science/retinoto_py/.venv/lib/python3.14/site-packages/optuna/study/_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app54_nextcloud/science/retinoto_py/.venv/lib/python3.14/site-packages/optuna/study/_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app54_nextcloud/science/retinoto_py/.venv/lib/python3.14/site-packages/optuna/study/_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app54_nextcloud/science/retinoto_py/.venv/lib/python3.14/site-packages/optuna/study/_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     18\u001b[39m scale = \u001b[32m100\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# args.im_mean = trial.suggest_float('im_mean', opt.im_mean / scale, opt.im_mean * scale, log=True)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# args.im_std = trial.suggest_float('im_std', opt.im_std / scale, opt.im_std * scale, log=True)\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# get the architecture of the network, train and get accuracy on the validation set\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m _, df_train = \u001b[43mfovea\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m accuracy = df_train[\u001b[33m'\u001b[39m\u001b[33macc_val\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app54_nextcloud/science/retinoto_py/src/retinoto_py/retinoto_py.py:156\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(args, model, train_loader, val_loader, df_train, model_filename, json_filename)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    args = fovea.Params(do_fovea=True, num_epochs=1, verbose=False)\n",
    "    model = fovea.load_model(args, model_filename=model_filename)\n",
    "\n",
    "    args.batch_size = trial.suggest_int('batch_size', 16, 512, log=True, step=1)\n",
    "    args.rs_min = trial.suggest_float('rs_min', -1, 1.)\n",
    "    args.rs_max = trial.suggest_float('rs_max', -7, -4)\n",
    "    \n",
    "    scale = 10\n",
    "    if args.delta2>0: args.delta2 = trial.suggest_float('delta2', args.delta2 / scale, min((args.delta2 * scale, 1)), log=True)\n",
    "    args.lr = trial.suggest_float('lr', args.lr / scale, args.lr * scale, log=True)\n",
    "\n",
    "    args.delta1 = trial.suggest_float('delta1', args.delta1 / scale, min((args.delta1 * scale, 1)), log=True)\n",
    "    if args.weight_decay>0: args.weight_decay = trial.suggest_float('weight_decay', args.weight_decay / scale, args.weight_decay * scale, log=True)\n",
    "    if args.label_smoothing>0: args.label_smoothing = trial.suggest_float('label_smoothing', args.label_smoothing / scale, args.label_smoothing * scale, log=True)\n",
    "\n",
    "    scale = 100 \n",
    "\n",
    "    # args.im_mean = trial.suggest_float('im_mean', opt.im_mean / scale, opt.im_mean * scale, log=True)\n",
    "    # args.im_std = trial.suggest_float('im_std', opt.im_std / scale, opt.im_std * scale, log=True)\n",
    "\n",
    "\n",
    "    # get the architecture of the network, train and get accuracy on the validation set\n",
    "    train_dataset.transform = train_dataset.transform = fovea.get_preprocess(args)   # <-- new callable is attached\n",
    "\n",
    "    train_loader = fovea.get_loader(args, train_dataset)\n",
    "    val_loader = fovea.get_loader(args, val_dataset)\n",
    "    _, df_train = fovea.train_model(args, model=model, train_loader=train_loader, val_loader=val_loader)\n",
    "    accuracy = df_train['acc_val'].mean()\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(storage=f\"sqlite:///cached_data/34_optuna.sqlite3\", \n",
    "                            sampler=optuna.samplers.TPESampler(multivariate=False, warn_independent_sampling=False),\n",
    "                            direction='maximize', load_if_exists=True, study_name=f\"34_optuna\")\n",
    "print(f'Starting optimization with params: {args} on {max(150-len(study.trials), 0)} trials - {len(study.trials)} ')\n",
    "study.optimize(objective, n_trials=max((150-len(study.trials), 0)), n_jobs=1, show_progress_bar=True)\n",
    "\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(\"Best Trial: \", study.best_trial)\n",
    "# print(\"Trials: \", study.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ed848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization.matplotlib as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8381f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = study.trials_dataframe()   \n",
    "params = sorted({k for t in study.trials for k in t.params})\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = fovea.plt.subplots(len(params), 1, figsize=(15, 8*len(params)), sharey=True)\n",
    "\n",
    "for ax, pname in zip(axes, params):\n",
    "    xs = [t.params[pname] for t in study.trials if pname in t.params]\n",
    "    ys = [t.value for t in study.trials if pname in t.params]\n",
    "    ax.scatter(xs, ys, s=20, alpha=0.6)\n",
    "    ax.set_xlabel(pname)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel(\"Objective\")\n",
    "\n",
    "fovea.plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f988b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.plot_contour(study, params=[\"weight_quanta\", \"resample_rate\"])\n",
    "# vis.plot_contour(study, params=[\"num_particles\", \"chunk_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7d113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04a1f98f9959468b8571c3f97d8c1c0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0856d0748d3e43d680900eef2ed9eae1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_145889df3ed746eea9765c0e08189f7d",
       "placeholder": "​",
       "style": "IPY_MODEL_fcb913d589814abfa17dbb8d3700e8f9",
       "tabbable": null,
       "tooltip": null,
       "value": " 0/56 [00:07&lt;?, ?it/s]"
      }
     },
     "121ffab421e34fd3bd3cb83a5779bacf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "145889df3ed746eea9765c0e08189f7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18afdf4102b744d6abc4af11463c0e56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41dd69f7b2bf453ba247b050711925bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98f18e766a9e4e8f909a90dc5ee01d54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_41dd69f7b2bf453ba247b050711925bd",
       "placeholder": "​",
       "style": "IPY_MODEL_121ffab421e34fd3bd3cb83a5779bacf",
       "tabbable": null,
       "tooltip": null,
       "value": "  0%"
      }
     },
     "b395ff50f8084a43b0b81c78855ac420": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6c7929ce98a4eb18d60af7b219d1c7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18afdf4102b744d6abc4af11463c0e56",
       "max": 56,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_04a1f98f9959468b8571c3f97d8c1c0c",
       "tabbable": null,
       "tooltip": null,
       "value": 0
      }
     },
     "eb60a2f6101543c19a4e5bd4e7661b61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_98f18e766a9e4e8f909a90dc5ee01d54",
        "IPY_MODEL_b6c7929ce98a4eb18d60af7b219d1c7d",
        "IPY_MODEL_0856d0748d3e43d680900eef2ed9eae1"
       ],
       "layout": "IPY_MODEL_b395ff50f8084a43b0b81c78855ac420",
       "tabbable": null,
       "tooltip": null
      }
     },
     "fcb913d589814abfa17dbb8d3700e8f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
