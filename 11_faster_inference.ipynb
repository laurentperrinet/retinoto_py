{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0de904",
   "metadata": {},
   "source": [
    "Dans ce script, nous allons tester diffÃ©rents modÃ¨les de type convolutionnelsur le dataset \n",
    "\n",
    "rÃ©sultat:\n",
    "* l'utilisation des batchs rend l'infÃ©rence globale plus rapide\n",
    "* un modÃ¨le a besoin de beaucoup de temps / parametres pour arriver Ã  un certain niveau d'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efdb6e14-6ce3-481d-9afc-61b1cfee1168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T10:45:23.376798Z",
     "iopub.status.busy": "2025-04-26T10:45:23.376511Z",
     "iopub.status.idle": "2025-04-26T10:45:36.118070Z",
     "shell.execute_reply": "2025-04-26T10:45:36.117553Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome on macOS-26.1-arm64-arm-64bit-Mach-O\t user laurent\tRunning on MPS device (Apple Silicon/MacOS)\t - macos_version = 26.1\t with device mps, pytorch==2.9.1\n",
      "Random seed 1998 has been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Params(image_size=224, do_mask=False, do_fovea=False, rs_min=0.0, rs_max=-5.0, padding_mode='zeros', seed=1998, batch_size=64, num_workers=4, in_memory=True, model_name='resnet101', do_scratch=False, num_epochs=10, n_train_stop=32768, n_val_stop=4096, lr=0.001, delta1=0.05, delta2=0.0, weight_decay=0.003, label_smoothing=0.0001, shuffle=True, verbose=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import retinoto_py as fovea\n",
    "args = fovea.Params(do_mask=False)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f4302",
   "metadata": {},
   "source": [
    "# testing a ResNet50 model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266f8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_DATA_DIR = args.DATAROOT / 'Imagenet_full' / 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15947f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset = fovea.get_dataset(args, VAL_DATA_DIR, n_stop=args.n_val_stop)\n",
    "# val_loader = fovea.get_loader(args, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06229308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¢ Parameter Count:\n",
      "  Total:     44,549,160\n",
      "  Trainable: 44,549,160\n",
      "--------------------------------------------------\n",
      "ðŸ§± Layer Count:\n",
      "  Total Modules (nn.Module): 287\n",
      "  Convolutional (nn.Conv2d): 104\n",
      "  Linear (nn.Linear): 1\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "model = fovea.load_model(args)\n",
    "model.eval()\n",
    "# --- Parameter Counts ---\n",
    "param_stats = fovea.count_parameters(model)\n",
    "print(\"ðŸ”¢ Parameter Count:\")\n",
    "print(f\"  Total:     {param_stats['total_parameters']:,}\")\n",
    "print(f\"  Trainable: {param_stats['trainable_parameters']:,}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Layer Counts ---\n",
    "print(\"ðŸ§± Layer Count:\")\n",
    "# 1. Total number of nn.Module objects\n",
    "total_layers = fovea.count_layers(model)\n",
    "print(f\"  Total Modules (nn.Module): {total_layers}\")\n",
    "\n",
    "# 2. Counting specific layer types\n",
    "from torch import nn\n",
    "\n",
    "conv_layers = fovea.count_layers(model, layer_type=nn.Conv2d)\n",
    "linear_layers = fovea.count_layers(model, layer_type=nn.Linear)\n",
    "print(f\"  Convolutional (nn.Conv2d): {conv_layers}\")\n",
    "print(f\"  Linear (nn.Linear): {linear_layers}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a025494d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24528f8d8ee5463dae9180f18816a8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Putting images in memory:   0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import datasets\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "def torch_loader(path: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load an image file using torchvision.io.read_image.\n",
    "    The returned tensor is float32 in the range [0, 1] and has shape (C, H, W).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Full path to the image file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Float tensor ready for torchvision transforms.\n",
    "    \"\"\"\n",
    "    # read_image returns a UInt8 tensor (C, H, W) with values 0â€‘255\n",
    "    img = read_image(path)                # still on CPU\n",
    "    # Convert to float and normalise\n",
    "    img = img.float() / 255.0\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2â€‘channel / 1â€‘channel handling (most transforms expect 3 channels)\n",
    "    # -----------------------------------------------------------------\n",
    "    if img.shape[0] == 1:                 # grayscale â†’ replicate to 3 channels\n",
    "        img = img.repeat(3, 1, 1)\n",
    "    elif img.shape[0] == 4:               # RGBA â†’ drop alpha (or you could blend)\n",
    "        img = img[:3, :, :]                # keep only RGB\n",
    "    elif img.shape[0] not in (3,):\n",
    "        raise RuntimeError(f\"Unsupported number of channels ({img.shape[0]}) in {path}\")\n",
    "\n",
    "    return img\n",
    "\n",
    "class InMemoryImageDataset(Dataset):\n",
    "    \"\"\"Load entire ImageFolder dataset into memory\"\"\"\n",
    "    def __init__(self, root, transform=None, n_stop=0, is_valid_file=None):\n",
    "        # Use ImageFolder to handle directory structure and class mapping\n",
    "        image_folder = datasets.ImageFolder(root=root, \n",
    "                                            loader=torch_loader,\n",
    "                                            is_valid_file=is_valid_file,\n",
    "                                            transform=None, \n",
    "                                            )\n",
    "        \n",
    "        self.class_to_idx = image_folder.class_to_idx\n",
    "        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "        self.classes = image_folder.classes\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load all images into memory\n",
    "        # print(\"Loading dataset into memory...\")\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        if n_stop==0:\n",
    "            n_total = len(image_folder)\n",
    "            idxs = np.arange(n_total) \n",
    "        else:\n",
    "            n_total = min((n_stop, len(image_folder)))\n",
    "            idxs = np.random.permutation(len(image_folder))[:n_total].astype(int)\n",
    "\n",
    "        for idx in tqdm(idxs, desc='Putting images in memory', total=n_total, leave=False):\n",
    "            self.images.append(image_folder[idx][0])\n",
    "            self.labels.append(image_folder[idx][1])\n",
    "\n",
    "        # print(f\"Loaded {len(self.images)} images into memory\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "\n",
    "dataset = InMemoryImageDataset(root=VAL_DATA_DIR, transform=None, n_stop=args.n_val_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f888652d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.InMemoryImageDataset at 0x12f4a3e00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33af4193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4767761b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 441, 500])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27d0cef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdee18b1fd14d4b94d8f3ce0fdd866b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Putting images in memory:   0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781366b55d894904a5c66909a2f56a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating resnet101 on dataset: full:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "json_filename = args.data_cache / '11_model_accuracy.json'\n",
    "\n",
    "# %rm -f {json_filename}  # FORCING RECOMPUTE\n",
    "\n",
    "if json_filename.exists():\n",
    "    results = fovea.pd.read_json(json_filename)\n",
    "else:\n",
    "    all_results_list = []\n",
    "    for dataset in ['full']:# <HACK until bbox is finished> fovea.all_datasets:\n",
    "        VAL_DATA_DIR = args.DATAROOT / f'Imagenet_{dataset}' / 'val'\n",
    "        val_dataset = fovea.get_dataset(args, VAL_DATA_DIR, n_stop=args.n_val_stop)\n",
    "        val_loader = fovea.get_loader(args, val_dataset)\n",
    "        accuracy = fovea.get_validation_accuracy(args, model, val_loader, f\"Evaluating {args.model_name} on dataset: {dataset}\")\n",
    "        all_results_list.append({'model_name':args.model_name, 'dataset':dataset, 'accuracy': accuracy})\n",
    "\n",
    "    results = fovea.pd.DataFrame(all_results_list)\n",
    "    results['accuracy_str'] = results['accuracy'].apply(lambda x: f\"Accuracy: {x * 100:.1f}%\")\n",
    "    results.to_json(json_filename, orient='records', indent=2)\n",
    "\n",
    "print(f\"Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0ad2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet101</td>\n",
       "      <td>full</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>Accuracy: 82.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name dataset  accuracy     accuracy_str\n",
       "0  resnet101    full  0.820312  Accuracy: 82.0%"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "241445c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for full: 82.031%\n"
     ]
    }
   ],
   "source": [
    "for _, row in results.iterrows():\n",
    "    accuracy_percent = row['accuracy'] * 100\n",
    "    print(f\"Accuracy for {row['dataset']}: {accuracy_percent:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4f86c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"model_name\":\"resnet101\",\n",
      "    \"dataset\":\"full\",\n",
      "    \"accuracy\":0.8203125,\n",
      "    \"accuracy_str\":\"Accuracy: 82.0%\"\n",
      "  }\n",
      "]"
     ]
    }
   ],
   "source": [
    "%cat {json_filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01cb5c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset    accuracy_str\n",
      "   full Accuracy: 82.0%\n"
     ]
    }
   ],
   "source": [
    "print(results[['dataset', 'accuracy_str']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
