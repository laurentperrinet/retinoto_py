{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce09631-1c66-4af0-b7fa-08e78d32a471",
   "metadata": {},
   "source": [
    "Building likelihood maps for a set of representative images.\n",
    "\n",
    "> TODO: use images from dataset and superimpose the bounding boxes on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8130a92-df14-4988-a525-d2f2d9f68f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:35:20.433866Z",
     "iopub.status.busy": "2025-04-26T09:35:20.433584Z",
     "iopub.status.idle": "2025-04-26T09:35:32.469394Z",
     "shell.execute_reply": "2025-04-26T09:35:32.468897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome on macOS-26.1-arm64-arm-64bit-Mach-O\t- Timestamp (UTC)  2025-12-03_16-04-14\t user laurentperrinet\tRunning on MPS device (Apple Silicon/MacOS)\t - macos_version = 26.1\t with device mps, pytorch==2.9.1\n",
      "Random seed 2018 has been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Params(image_size=224, do_mask=False, do_fovea=False, rs_min=0.0, rs_max=-5.0, padding_mode='zeros', seed=2018, batch_size=6, num_workers=0, in_memory=True, model_name='convnext_base', do_scratch=False, num_epochs=20, n_train_stop=65536, n_val_stop=6, lr=3e-06, delta1=0.05, delta2=0.01, weight_decay=0.02, label_smoothing=0.03, shuffle=True, verbose=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import retinoto_py as fovea\n",
    "N_show = 6\n",
    "args = fovea.Params(batch_size=N_show, do_mask=False, n_val_stop=N_show)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13479bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(full_image) = <class 'torch.Tensor'>, full_image.dtype = torch.float32, full_image.shape = torch.Size([3, 587, 800])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image\n",
    "\n",
    "alpha = .5\n",
    "s_max = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1899d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAL_DATA_DIR = args.DATAROOT / 'Imagenet_bbox' / 'val'\n",
    "\n",
    "# args = fovea.Params(batch_size=N_show, do_mask=False, n_val_stop=N_show)\n",
    "# val_dataset = fovea.get_dataset(args, VAL_DATA_DIR, n_stop=N_show)\n",
    "# val_loader = fovea.get_loader(args, val_dataset, seed=seed)\n",
    "# for images, labels in val_loader:\n",
    "#     images, labels = images.to('cpu'), labels.to('cpu')\n",
    "#     break\n",
    "# fig, ax = fovea.imshow(images, fig_height=5)\n",
    "# fovea.plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6e1fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels from local cache cached_data/imagenet_class_index.json...\n",
      "Loading labels from local cache cached_data/imagenet_class_index.json...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_label = fovea.get_idx_to_label(args)\n",
    "label2idx = fovea.get_label_to_idx(args)\n",
    "label2idx['impala']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eef4fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great_grey_owl\n",
      "howler_monkey\n",
      "mixing_bowl\n",
      "soup_bowl\n"
     ]
    }
   ],
   "source": [
    "for key in label2idx.keys(): \n",
    "    if 'owl' in key: print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4079936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading .... cached_data/33_fovea_model_name=convnext_base_dataset=bbox.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('cached_data/33_fovea_model_name=convnext_base_dataset=bbox.pth')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'bbox'\n",
    "model_filename = args.data_cache / f'33_fovea_model_name={args.model_name}_dataset={dataset}.pth'\n",
    "model = fovea.load_model(args, model_filename=model_filename)\n",
    "model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c223451-98af-4ed1-ab56-838b4deaf5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:35:32.471565Z",
     "iopub.status.busy": "2025-04-26T09:35:32.471195Z",
     "iopub.status.idle": "2025-04-26T09:35:33.438316Z",
     "shell.execute_reply": "2025-04-26T09:35:33.437592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(full_image) = <class 'torch.Tensor'>, full_image.dtype = torch.float32, full_image.shape = torch.Size([3, 587, 800])\n"
     ]
    }
   ],
   "source": [
    "for image_url, true_label in  [('./images/jaguar_5.jpg',  'jaguar'),\n",
    "                                ('./images/frog.jpg',  'tree_frog'),\n",
    "                                ('./images/Hidden_snow_leopard.png',  'snow_leopard'),\n",
    "                                ('./images/Hidden_leopard.png',  'leopard'),\n",
    "                                ('./images/Hidden_giraffe.png',  'giraffe'),\n",
    "                                ('./images/Hidden_tiger.png',  'tiger'),\n",
    "                                ('./images/Hidden_owl.png',  'great_grey_owl'),\n",
    "                                ('./images/wolf.jpg',  'wolf'),\n",
    "                                ]:\n",
    "    full_image = read_image(image_url)[:3, :, :]/255\n",
    "    full_image_np = torch.movedim(full_image, (1, 2, 0), (0, 1, 2)).numpy()\n",
    "    print(f\"{type(full_image) = }, {full_image.dtype = }, {full_image.shape = }\")\n",
    "\n",
    "    pos_H, pos_W, outputs = fovea.compute_likelihood_map(args, model, full_image, size_ratio=.6)\n",
    "    outputs = outputs.cpu()\n",
    "    logit_label = outputs[:, label2idx[true_label]]\n",
    "    idx_max = logit_label.argmax()\n",
    "\n",
    "\n",
    "    fig, ax = fovea.plt.subplots()\n",
    "    ax.imshow(full_image_np)\n",
    "    ax.scatter(pos_W.ravel(), pos_H.ravel(), s=logit_label.abs()*s_max, c=logit_label, alpha=alpha, edgecolors='none', cmap='coolwarm', vmin=-max(abs(logit_label)), vmax=max(abs(logit_label)),)\n",
    "\n",
    "    ax.scatter(pos_W.ravel()[idx_max], pos_H.ravel()[idx_max], s=logit_label[idx_max]*s_max, marker='*', c='white', alpha=alpha)\n",
    "    fig.set_facecolor(color='white')\n",
    "    fovea.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964687b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
