{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5947a950",
   "metadata": {},
   "source": [
    "In this notebook we use the bounding boxes given with the [Imagenet data set](https://www.kaggle.com/c/imagenet-object-localization-challenge) to generate a new sub-set. From the original data set `Imagenet_full` by only keeping the smallest square comprising the bounding boxe we generate `Imagenet_bbox` sub-set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529b0d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:02.181783Z",
     "iopub.status.busy": "2025-07-30T15:42:02.181371Z",
     "iopub.status.idle": "2025-07-30T15:42:02.188788Z",
     "shell.execute_reply": "2025-07-30T15:42:02.188361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params(image_size=224, do_mask=False, do_fovea=False, rs_min=0.0, rs_max=-5.0, padding_mode='zeros', seed=2018, batch_size=1, num_workers=4, in_memory=True, model_name='resnet101', do_scratch=False, num_epochs=20, n_train_stop=40960, n_val_stop=5120, do_full_training=False, lr=1e-05, delta1=0.05, delta2=0.0, weight_decay=0.0, label_smoothing=0.0, shuffle=False, verbose=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import retinoto_py as fovea\n",
    "args = fovea.Params(batch_size=1, shuffle=False)\n",
    "args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066350cf",
   "metadata": {},
   "source": [
    "## reading localisation metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d318a6",
   "metadata": {},
   "source": [
    "First for the 'train' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40616b39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:02.196358Z",
     "iopub.status.busy": "2025-07-30T15:42:02.196104Z",
     "iopub.status.idle": "2025-07-30T15:42:02.869278Z",
     "shell.execute_reply": "2025-07-30T15:42:02.868695Z"
    }
   },
   "outputs": [],
   "source": [
    "folder = 'train'\n",
    "annotation_file = args.DATAROOT / f'LOC_{folder}_solution.csv'\n",
    "\n",
    "with open(annotation_file, 'r') as csv_file:\n",
    "    df_data = fovea.pd.read_csv(csv_file)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40616b39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:02.196358Z",
     "iopub.status.busy": "2025-07-30T15:42:02.196104Z",
     "iopub.status.idle": "2025-07-30T15:42:02.869278Z",
     "shell.execute_reply": "2025-07-30T15:42:02.868695Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_boxes(df, value):\n",
    "    idx = list(df['ImageId'][df['ImageId'] == value].index)\n",
    "    bboxes = []\n",
    "    if idx:\n",
    "        for i in range(len(df[\"PredictionString\"][idx[0]].split(' '))//5):\n",
    "            pos =(5*i)\n",
    "            bboxes.append({'xmin' : int(df[\"PredictionString\"][idx[0]].split(' ')[1 + pos]),\n",
    "                           'ymin' : int(df[\"PredictionString\"][idx[0]].split(' ')[2 + pos]),\n",
    "                           'xmax' : int(df[\"PredictionString\"][idx[0]].split(' ')[3 + (5 *i)]),\n",
    "                           'ymax' : int(df[\"PredictionString\"][idx[0]].split(' ')[4 + (5 *i)])\n",
    "                                        })\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05654602",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_boxes(df_data, 'n02099849_2300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0201adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:02.871502Z",
     "iopub.status.busy": "2025-07-30T15:42:02.871212Z",
     "iopub.status.idle": "2025-07-30T15:42:02.932732Z",
     "shell.execute_reply": "2025-07-30T15:42:02.932299Z"
    }
   },
   "outputs": [],
   "source": [
    "get_boxes(df_data, 'n01440764_32420')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0f459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:02.934629Z",
     "iopub.status.busy": "2025-07-30T15:42:02.934363Z",
     "iopub.status.idle": "2025-07-30T15:42:02.991294Z",
     "shell.execute_reply": "2025-07-30T15:42:02.990886Z"
    }
   },
   "source": [
    "Now for the 'val' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fd370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:02.993147Z",
     "iopub.status.busy": "2025-07-30T15:42:02.992898Z",
     "iopub.status.idle": "2025-07-30T15:42:03.073270Z",
     "shell.execute_reply": "2025-07-30T15:42:03.072832Z"
    }
   },
   "outputs": [],
   "source": [
    "folder = 'val'\n",
    "annotation_file = args.DATAROOT / f'LOC_{folder}_solution.csv'\n",
    "\n",
    "with open(annotation_file, 'r') as csv_file:\n",
    "    df_data = fovea.pd.read_csv(csv_file)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fd370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:02.993147Z",
     "iopub.status.busy": "2025-07-30T15:42:02.992898Z",
     "iopub.status.idle": "2025-07-30T15:42:03.073270Z",
     "shell.execute_reply": "2025-07-30T15:42:03.072832Z"
    }
   },
   "outputs": [],
   "source": [
    "get_boxes(df_data, 'ILSVRC2012_val_00026171')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3d506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:03.075159Z",
     "iopub.status.busy": "2025-07-30T15:42:03.074886Z",
     "iopub.status.idle": "2025-07-30T15:42:03.085568Z",
     "shell.execute_reply": "2025-07-30T15:42:03.085148Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Répertoire des images de validation (adapter si nécessaire)\n",
    "val_dir = args.DATAROOT / 'Imagenet_full' / 'val'\n",
    "N_show = 12\n",
    "# Choisir quelques images (ici les 8 premières ImageId présentes dans df_data)\n",
    "image_ids = df_data['ImageId'].unique()[:N_show].tolist()\n",
    "image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f986dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "\n",
    "n = len(image_ids)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "fig, axes = fovea.plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax_idx, imgid in enumerate(image_ids):\n",
    "    ax = axes[ax_idx]\n",
    "    # trouver le fichier d'image correspondant (quelque soit l'extension)\n",
    "    files = list(val_dir.rglob(f'{imgid}.*'))\n",
    "    if not files:\n",
    "        ax.set_title(f'{imgid} not found')\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "    img_path = files[0]\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # récupérer les boîtes depuis df_data via la fonction get_boxes définie plus haut\n",
    "    boxes = get_boxes(df_data, imgid)\n",
    "    for b in boxes:\n",
    "        xmin, ymin, xmax, ymax = b['xmin'], b['ymin'], b['xmax'], b['ymax']\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        rect = Rectangle((xmin, ymin), w, h, linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.set_title(imgid)\n",
    "    ax.axis('off')\n",
    "\n",
    "# masquer les axes restants si nécessaire\n",
    "for i in range(len(image_ids), rows*cols):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "fovea.plt.tight_layout()\n",
    "fovea.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b18e4",
   "metadata": {},
   "source": [
    "## cropping and padding images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bbox_to_square(xmin, ymin, xmax, ymax, margin: int = 0):\n",
    "    \"\"\"Retourne (cx, cy, size) du plus petit carré contenant la bbox + marge (en pixels).\"\"\"\n",
    "    w = xmax - xmin\n",
    "    h = ymax - ymin\n",
    "    size = int(round(max(w, h))) + int(margin)\n",
    "    cx = (xmin + xmax) / 2.0\n",
    "    cy = (ymin + ymax) / 2.0\n",
    "    return cx, cy, size\n",
    "\n",
    "\n",
    "def crop_square_around_bbox(img, bbox, output_size=None, margin:int=0, fill=0):\n",
    "    \"\"\"\n",
    "    Crop (ou pad) un carré autour de bbox.\n",
    "    - img: PIL.Image ou torch.Tensor (C,H,W)\n",
    "    - bbox: (xmin, ymin, xmax, ymax) en pixels (image coordinates)\n",
    "    - output_size: None -> taille = taille du carré englobant ; sinon int ou (w,h)\n",
    "    - margin: pixels à ajouter au carré avant crop\n",
    "    - fill: valeur de remplissage pour le padding (int ou tuple)\n",
    "    Retourne le patch (PIL.Image ou torch.Tensor selon l'input).\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    cx, cy, size = bbox_to_square(xmin, ymin, xmax, ymax, margin=margin)\n",
    "\n",
    "    if output_size is None:\n",
    "        ow = oh = size\n",
    "    elif isinstance(output_size, int):\n",
    "        ow = oh = output_size\n",
    "    else:\n",
    "        ow, oh = output_size\n",
    "\n",
    "    left = int(round(cx - ow / 2))\n",
    "    top = int(round(cy - oh / 2))\n",
    "    right = left + ow\n",
    "    bottom = top + oh\n",
    "\n",
    "    # PIL handling\n",
    "    if isinstance(img, fovea.Image.Image):\n",
    "        pad_left = max(0, -left)\n",
    "        pad_top = max(0, -top)\n",
    "        pad_right = max(0, right - img.width)\n",
    "        pad_bottom = max(0, bottom - img.height)\n",
    "        if any((pad_left, pad_top, pad_right, pad_bottom)):\n",
    "            img = fovea.TF.pad(img, (pad_left, pad_top, pad_right, pad_bottom), fill=fill)\n",
    "            left += pad_left\n",
    "            top += pad_top\n",
    "        return fovea.TF.crop(img, top, left, oh, ow)\n",
    "\n",
    "    # Tensor handling (C,H,W)\n",
    "    if isinstance(img, fovea.torch.Tensor):\n",
    "        _, H, W = img.shape\n",
    "        pad_left = max(0, -left)\n",
    "        pad_top = max(0, -top)\n",
    "        pad_right = max(0, right - W)\n",
    "        pad_bottom = max(0, bottom - H)\n",
    "        if any((pad_left, pad_top, pad_right, pad_bottom)):\n",
    "            # TF.pad accepts tensors; padding tuple is (left, top, right, bottom)\n",
    "            img = fovea.TF.pad(img, (pad_left, pad_top, pad_right, pad_bottom), fill=fill)\n",
    "            left += pad_left\n",
    "            top += pad_top\n",
    "        return img[:, top:top + oh, left:left + ow]\n",
    "\n",
    "    # fallback: convert to PIL and ré-appeler\n",
    "    img_pil = fovea.TF.to_pil_image(img)\n",
    "    return crop_square_around_bbox(img_pil, bbox, output_size=(ow,oh), margin=0, fill=fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = fovea.plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "rel_margin = .1 # margin computed relative to the diagonal length of the bnounding box\n",
    "\n",
    "for ax_idx, imgid in enumerate(image_ids):\n",
    "    ax = axes[ax_idx]\n",
    "    # trouver le fichier d'image correspondant (quelque soit l'extension)\n",
    "    files = list(val_dir.rglob(f'{imgid}.*'))\n",
    "    if not files:\n",
    "        ax.set_title(f'{imgid} not found')\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "    img_path = files[0]\n",
    "    img = fovea.Image.open(img_path).convert('RGB')\n",
    "    boxes = get_boxes(df_data, imgid)\n",
    "    b = boxes[0]\n",
    "    xmin, ymin, xmax, ymax = b['xmin'], b['ymin'], b['xmax'], b['ymax']\n",
    "    margin = int( fovea.np.sqrt(((xmax-xmin)**2 + (ymax-ymin)**2)) * rel_margin )\n",
    "    img_crop = crop_square_around_bbox(img, [xmin, ymin, xmax, ymax], margin=margin)\n",
    "    ax.imshow(img_crop)\n",
    "\n",
    "    ax.set_title(imgid)\n",
    "    ax.axis('off')\n",
    "\n",
    "# masquer les axes restants si nécessaire\n",
    "for i in range(len(image_ids), rows*cols):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "fovea.plt.tight_layout()\n",
    "fovea.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6913543",
   "metadata": {},
   "source": [
    "## Building the new dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01364be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(list_dir, EXCLUDED_FILES={'.DS_Store', '.ipynb_checkpoints'}):\n",
    "    return [ p for p in list_dir if p.is_file() and p.name not in EXCLUDED_FILES  ]\n",
    "    \n",
    "FULL_DATA_DIR = args.DATAROOT / 'Imagenet_full'\n",
    "src_root = FULL_DATA_DIR / 'val'\n",
    "for img_path in clean_list(list(src_root.rglob('*.*'))):\n",
    "    print(f'File {img_path} decomposes into a class_id = {img_path.parent.name} and a imgid = {img_path.stem}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c8b17-e9b4-49b4-960c-af08b4847224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T15:42:03.091747Z",
     "iopub.status.busy": "2025-07-30T15:42:03.091539Z",
     "iopub.status.idle": "2025-07-30T15:42:08.917271Z",
     "shell.execute_reply": "2025-07-30T15:42:08.916777Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "FULL_DATA_DIR = args.DATAROOT / 'Imagenet_full'\n",
    "BBOX_DATA_DIR = args.DATAROOT / 'Imagenet_bbox'\n",
    "BBOX_DATA_DIR.mkdir(exist_ok=True)\n",
    "IMG_EXTS = {'.jpg', '.jpeg', '.JPEG', '.png', '.bmp'}\n",
    "\n",
    "# parameters for the new dataset\n",
    "format = 'png' # lossless encoding\n",
    "rel_margin = .1 # margin computed relative to the diagonal length of the bnounding box\n",
    "\n",
    "for folder in ['val', 'train']:\n",
    "# for folder in ['train']:\n",
    "    print(f'\\n Scanning folder \"{folder}\"')\n",
    "    annotation_file = args.DATAROOT / f'LOC_{folder}_solution.csv'\n",
    "    with open(annotation_file, 'r') as csv_file:\n",
    "        df_data = fovea.pd.read_csv(csv_file)\n",
    "\n",
    "    src_root = FULL_DATA_DIR / folder\n",
    "    tgt_root = BBOX_DATA_DIR / folder\n",
    "    tgt_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    count_in = 0\n",
    "    count_out = 0\n",
    "\n",
    "    # parcours récursif avec pathlib\n",
    "    for img_path in fovea.tqdm(clean_list(list(src_root.rglob('*.*')))):\n",
    "        if not img_path.is_file() or img_path.suffix not in IMG_EXTS:\n",
    "            print(f'File {img_path} is detected as an invalid image.')\n",
    "            continue\n",
    "\n",
    "        count_in += 1\n",
    "        imgid = img_path.stem\n",
    "        # Get the list of bounding boxes for a specific image. If that list is empty (meaning no boxes were found for this image), then skip to the next image and don't run any code that comes after this line.\n",
    "        boxes = get_boxes(df_data, imgid)\n",
    "        if not boxes:\n",
    "            continue\n",
    "\n",
    "        class_id = img_path.parent.name\n",
    "        target_folder = tgt_root / class_id\n",
    "        target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        original_image = None\n",
    "        for i_obj, b in enumerate(boxes):\n",
    "            no = '' if i_obj == 0 else f'_{i_obj}'\n",
    "            out_path = target_folder / f'{imgid}{no}.{format}'\n",
    "            if out_path.is_file():\n",
    "                # the file already exists let's skip it\n",
    "                count_out += 1\n",
    "                continue\n",
    "\n",
    "            if original_image is None:\n",
    "                try:\n",
    "                    original_image = Image.open(img_path).convert('RGB')\n",
    "                except Exception as e:\n",
    "                    print(f'  could not open {img_path}: {e}')\n",
    "                    break\n",
    "\n",
    "            xmin, ymin, xmax, ymax = b['xmin'], b['ymin'], b['xmax'], b['ymax']\n",
    "            margin = int( fovea.np.sqrt(((xmax-xmin)**2 + (ymax-ymin)**2)) * rel_margin )\n",
    "            crop_image = crop_square_around_bbox(original_image, (xmin, ymin, xmax, ymax), margin=margin)\n",
    "            crop_image.save(out_path, format='PNG')\n",
    "            count_out += 1\n",
    "\n",
    "    print(f' - in: {count_in} / out: {count_out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4327c3b",
   "metadata": {},
   "source": [
    "## Showcasing the new dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = args.DATAROOT / 'Imagenet_bbox' / 'val'\n",
    "\n",
    "fig, axes = fovea.plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax_idx, imgid in enumerate(image_ids):\n",
    "    ax = axes[ax_idx]\n",
    "    # trouver le fichier d'image correspondant (quelque soit l'extension)\n",
    "    files = list(val_dir.rglob(f'{imgid}.*'))\n",
    "    if not files:\n",
    "        ax.set_title(f'{imgid} not found')\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "    img_path = files[0]\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    ax.imshow(img)\n",
    "\n",
    "    ax.set_title(imgid)\n",
    "    ax.axis('off')\n",
    "\n",
    "# masquer les axes restants si nécessaire\n",
    "for i in range(len(image_ids), rows*cols):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "fovea.plt.tight_layout()\n",
    "fovea.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff4434",
   "metadata": {},
   "source": [
    "## Debugging the new dataset for `from torchvision.io import read_image`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4291ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import retinoto_py as fovea\n",
    "args = fovea.Params(batch_size=1, shuffle=False)\n",
    "args\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_TEXT_CHUNK = 10 * 1024 * 1024   # 10 MiB (choose a value > largest chunk)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_png(image_path):\n",
    "    \"\"\"Re-encode PNG cleanly without ICC profile\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        # Convert to RGB if needed, save cleanly\n",
    "        if img.mode == 'RGBA':\n",
    "            img = img.convert('RGB')\n",
    "        img.save(image_path, 'PNG')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "for data_dir in [args.DATAROOT / 'Imagenet_bbox' / 'val', args.DATAROOT / 'Imagenet_bbox' / 'train']:\n",
    "    for png_file in fovea.tqdm(list(data_dir.rglob(\"*.png\"))):\n",
    "        clean_png(str(png_file))\n",
    "        # print(f\"Cleaned: {png_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733e049",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "def inspect_png_chunks(filepath):\n",
    "    \"\"\"Read PNG chunks and report text chunk sizes\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        # PNG signature\n",
    "        if f.read(8) != b'\\x89PNG\\r\\n\\x1a\\n':\n",
    "            return None\n",
    "        \n",
    "        chunks = []\n",
    "        while True:\n",
    "            length_bytes = f.read(4)\n",
    "            if len(length_bytes) < 4:\n",
    "                break\n",
    "            \n",
    "            chunk_len = int.from_bytes(length_bytes, 'big')\n",
    "            chunk_type = f.read(4).decode('ascii', errors='ignore')\n",
    "            chunk_data = f.read(chunk_len)\n",
    "            crc = f.read(4)\n",
    "            \n",
    "            chunks.append((chunk_type, chunk_len))\n",
    "            \n",
    "            if chunk_type == 'IEND':\n",
    "                break\n",
    "        \n",
    "        return chunks\n",
    "\n",
    "# # Find problematic files\n",
    "# for png_file in data_dir.rglob(\"*.png\"):\n",
    "#     chunks = inspect_png_chunks(png_file)\n",
    "#     if chunks:\n",
    "#         for chunk_type, chunk_len in chunks:\n",
    "#             if chunk_type in ['tEXt', 'zTXt', 'iTXt'] and chunk_len > 128 * 1024:\n",
    "#                 print(f\"{png_file}: {chunk_type} chunk = {chunk_len / 1024:.1f} KiB\")\n",
    "\n",
    "def find_large_text_chunks(directory, size_limit=128*1024):\n",
    "    problematic = []\n",
    "    for png_file in Path(directory).rglob(\"*.png\"):\n",
    "        chunks = inspect_png_chunks(png_file)\n",
    "        if chunks:\n",
    "            for chunk_type, chunk_len in chunks:\n",
    "                if chunk_type in ['tEXt', 'zTXt', 'iTXt'] and chunk_len > size_limit:\n",
    "                    problematic.append({\n",
    "                        'file': str(png_file),\n",
    "                        'chunk_type': chunk_type,\n",
    "                        'size_kb': chunk_len / 1024\n",
    "                    })\n",
    "    return problematic\n",
    "\n",
    "# Find all problematic files\n",
    "for data_dir in [args.DATAROOT / 'Imagenet_bbox' / 'val', args.DATAROOT / 'Imagenet_bbox' / 'train']:\n",
    "    issues = find_large_text_chunks(data_dir)\n",
    "    for issue in issues:\n",
    "        print(f\"{issue['file']}: {issue['chunk_type']} = {issue['size_kb']:.1f} KiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c3e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def strip_icc_profiles(img_path):\n",
    "    if img_path.name.lower().endswith('.png'):\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # Remove ICC profile if it exists\n",
    "            if 'icc_profile' in img.info:\n",
    "                img.info.pop('icc_profile')\n",
    "\n",
    "            img.save(img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "for data_dir in [args.DATAROOT / 'Imagenet_bbox' / 'val', args.DATAROOT / 'Imagenet_bbox' / 'train']:\n",
    "    for png_file in fovea.tqdm(list(data_dir.rglob(\"*.png\"))):\n",
    "        strip_icc_profiles(png_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_png_to_jpg(image_path):\n",
    "#     \"\"\"Re-encode PNG cleanly without ICC profile\"\"\"\n",
    "#     try:\n",
    "#         img = Image.open(image_path).convert('RGB')\n",
    "#         imgid = img_path.stem\n",
    "#         class_id = img_path.parent.name\n",
    "#         target_folder = tgt_root / class_id\n",
    "#         out_path = target_folder / f'{imgid}.jpg'        \n",
    "#         # https://pc-pillow.readthedocs.io/en/latest/Image_class/Image_save.html\n",
    "#         img.save(out_path, quality=95)\n",
    "#         image_path.unlink()\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\")\n",
    "#         return False\n",
    "\n",
    "# for data_dir in [args.DATAROOT / 'Imagenet_bbox' / 'val', args.DATAROOT / 'Imagenet_bbox' / 'train']:\n",
    "#     for png_file in fovea.tqdm(list(data_dir.rglob(\"*.png\"))):\n",
    "#         convert_png_to_jpg(str(png_file))\n",
    "#         # print(f\"Cleaned: {png_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05313685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: /Users/laurent/data/Imagenet/Imagenet_bbox/val\n",
      "Found 80475 PNG files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing PNG profiles: 100%|██████████| 80475/80475 [00:30<00:00, 2660.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully fixed 80475/80475 files\n",
      "\n",
      "Processing: /Users/laurent/data/Imagenet/Imagenet_bbox/train\n",
      "Found 615298 PNG files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing PNG profiles:  23%|██▎       | 139200/615298 [00:56<03:28, 2284.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /Users/laurent/data/Imagenet/Imagenet_bbox/train/n02087394/n02087394_22856.png: cannot identify image file '/Users/laurent/data/Imagenet/Imagenet_bbox/train/n02087394/n02087394_22856.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing PNG profiles:  56%|█████▌    | 343104/615298 [02:30<01:37, 2802.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /Users/laurent/data/Imagenet/Imagenet_bbox/train/n04536866/n04536866_12128_2.png: Decompressed data too large for PngImagePlugin.MAX_TEXT_CHUNK\n",
      "Error processing /Users/laurent/data/Imagenet/Imagenet_bbox/train/n04536866/n04536866_12128.png: Decompressed data too large for PngImagePlugin.MAX_TEXT_CHUNK\n",
      "Error processing /Users/laurent/data/Imagenet/Imagenet_bbox/train/n04536866/n04536866_12128_1.png: Decompressed data too large for PngImagePlugin.MAX_TEXT_CHUNK\n",
      "Error processing /Users/laurent/data/Imagenet/Imagenet_bbox/train/n04536866/n04536866_12128_3.png: Decompressed data too large for PngImagePlugin.MAX_TEXT_CHUNK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing PNG profiles:  95%|█████████▍| 583360/615298 [04:14<00:11, 2720.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /Users/laurent/data/Imagenet/Imagenet_bbox/train/n02119789/n02119789_17624.png: cannot identify image file '/Users/laurent/data/Imagenet/Imagenet_bbox/train/n02119789/n02119789_17624.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing PNG profiles: 100%|██████████| 615298/615298 [04:27<00:00, 2301.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully fixed 615292/615298 files\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fix malformed ICC profiles in PNG files by re-encoding them.\n",
    "Run this once on your ImageNet dataset to permanently remove the warnings.\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fix_png_profile(image_path):\n",
    "    \"\"\"\n",
    "    Remove ICC profile from a single PNG by re-encoding it.\n",
    "    Returns True if successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Convert RGBA to RGB if needed\n",
    "        if img.mode == 'RGBA':\n",
    "            rgb_img = Image.new('RGB', img.size, (255, 255, 255))\n",
    "            rgb_img.paste(img, mask=img.split()[3])\n",
    "            img = rgb_img\n",
    "        elif img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        # Save without ICC profile - this removes the malformed metadata\n",
    "        temp_path = image_path.with_suffix('.temp.png')\n",
    "        img.save(temp_path, 'PNG')\n",
    "        temp_path.replace(image_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def fix_all_pngs(root_dir, num_workers=-1):\n",
    "    \"\"\"\n",
    "    Recursively find and fix all PNG files in a directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    root_dir : Path\n",
    "        Root directory containing PNG files\n",
    "    num_workers : int\n",
    "        Number of parallel workers for processing\n",
    "    \"\"\"\n",
    "    png_files = list(root_dir.rglob(\"*.png\"))\n",
    "    \n",
    "    print(f\"Found {len(png_files)} PNG files to process\")\n",
    "    \n",
    "    if len(png_files) == 0:\n",
    "        print(\"No PNG files found!\")\n",
    "        return\n",
    "    \n",
    "    # Process in parallel with progress bar\n",
    "    results = Parallel(n_jobs=num_workers)(\n",
    "        delayed(fix_png_profile)(f) for f in tqdm(png_files, desc=\"Fixing PNG profiles\")\n",
    "    )\n",
    "    \n",
    "    successful = sum(results)\n",
    "    print(f\"\\nSuccessfully fixed {successful}/{len(png_files)} files\")\n",
    "\n",
    "\n",
    "for data_dir in [args.DATAROOT / 'Imagenet_bbox' / 'val', args.DATAROOT / 'Imagenet_bbox' / 'train']:\n",
    "    print(f\"\\nProcessing: {data_dir}\")\n",
    "    fix_all_pngs(data_dir, num_workers=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f437f203",
   "metadata": {},
   "source": [
    "Voilà !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
